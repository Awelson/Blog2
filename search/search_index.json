{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":""},{"location":"Coding%20Cookbook/","title":"Coding Cookbook","text":"<p>This is where I'll host snippets of code for doing certain things because I don't want to keep googling or asking AI everytime I forget.</p>"},{"location":"Coding%20Cookbook/#gitgithub","title":"Git/Github","text":""},{"location":"Coding%20Cookbook/#python","title":"Python","text":""},{"location":"Coding%20Cookbook/#r","title":"R","text":""},{"location":"Coding%20Cookbook/#sql","title":"SQL","text":""},{"location":"Lists/","title":"Lists","text":"<p>This is a section where I keep lists.. Lists of all sorts, YouTubers I find cool, anime I find cool, helpful resources I find cool, etc...</p> <ul> <li>Japanese Language Learning Resources (JLLR)</li> <li>Data Science / Statistics Resources (DSSR)</li> <li>Cool YouTube channels</li> </ul> <p>For even more lists, check out : Awesome Lists on Github</p>"},{"location":"Lists/DSSR/","title":"Data Science / Statistics Resources","text":""},{"location":"Lists/DSSR/#online-textbooks","title":"Online Textbooks","text":"<ul> <li>R for Data Science</li> <li>Advanced R</li> <li>Modern R with tidyverse</li> <li>Modern Statistics with R</li> <li>Computational Genomics with R</li> <li>Modern Dive</li> <li>Modern Data Visualization with R</li> <li>Bayes Rules!</li> <li>An Introduction to Bayesian Thinking</li> <li>Probabilistic Programming and Bayesian Methods for Hackers</li> <li>Applied Multivariate Statistics in R</li> <li>The Little Books of R</li> <li>The Art of Data Visualization with ggplot2</li> </ul> <p>Also worth checking out : Michael Clark - Documents</p>"},{"location":"Lists/DSSR/#blogs","title":"Blogs","text":"<ul> <li>Models Demystified</li> <li>Statistical Modeling, Causal Inference, and Social Science</li> <li>r-bloggers</li> <li>rviews</li> <li>rworks</li> <li>rweekly</li> <li>rfortherestofus</li> <li>The R Blog</li> <li>Jessjep</li> <li>Nicola Rennie</li> <li>Statistical Thinking</li> <li>Julia Slige</li> </ul>"},{"location":"Lists/DSSR/#yt-channels","title":"YT Channels","text":"<ul> <li>xvzf</li> <li>Very Normal</li> <li>Riffomonas Project</li> <li>Equitable Equations</li> <li>Simplistics (QuantPsych)</li> <li>PositPBC</li> <li>R Consortium</li> <li>PyData</li> </ul>"},{"location":"Lists/DSSR/#misc","title":"Misc","text":"<ul> <li>Data Science Roadmap</li> <li>Tidy Tuesday</li> <li>kaggle</li> </ul>"},{"location":"Lists/YT/","title":"Cool YouTube Channels","text":""},{"location":"Lists/YT/#video-essay","title":"Video Essay","text":"<ul> <li>David Bull</li> <li>SsethTzeentach</li> <li>Internet Historian</li> <li>LEMMiNO</li> <li>hbomberguy</li> <li>EmpLemon</li> <li>Solar Sands</li> <li>FUNKe</li> <li>Bobby Fingers</li> <li>DJ Peach Cobbler</li> <li>WhatsItLike</li> <li>Vsauce</li> <li>Emergent Garden</li> </ul>"},{"location":"Lists/YT/#stem","title":"STEM","text":"<ul> <li>VlogBrothers<ul> <li>HankGreen</li> <li>Scishow</li> </ul> </li> <li>Journey to the Microcosmos</li> <li>The Thought Emporium</li> <li>melodysheep</li> <li>Fractal Philosophy</li> </ul>"},{"location":"Lists/YT/#chemistry","title":"Chemistry","text":"<ul> <li>NileRed<ul> <li>NileBlue</li> </ul> </li> <li>Extractions&amp;Ire</li> <li>MrGreenGuy</li> </ul>"},{"location":"Lists/YT/#csprogrammingai","title":"CS/Programming/AI","text":"<ul> <li>Junferno</li> <li>carykh</li> <li>CodeParade</li> <li>A byte of code</li> <li>Purple Mind</li> <li>suckerpinch</li> <li>Rational Animations</li> <li>2swap</li> <li>Computerphile</li> <li>Freya Holmer</li> <li>Programming2.0</li> </ul>"},{"location":"Lists/YT/#maths","title":"Maths","text":"<ul> <li>Trefor Bazett</li> <li>Numberphile</li> <li>Sheafification of G</li> <li>Zundamon's Theorem</li> <li>Matthew Bolan</li> <li>MathProofsable</li> <li>Elliot Nicholson</li> <li>3b1b</li> <li>vcubingx</li> <li>Mathologer</li> <li>Wrath of Math</li> <li>Eyesomorphic</li> <li>AllAngles</li> <li>Diplomatic fish</li> <li>Eric Rownland</li> <li>Boppana Math</li> <li>Lines that connect</li> <li>Epsilon Delta</li> <li>Physics for the Birds</li> <li>zhuli</li> <li>Dr. Zye</li> </ul>"},{"location":"Lists/YT/#animation-music","title":"Animation / Music","text":"<ul> <li>beetlerat</li> <li>vewn</li> <li>u m a m i</li> <li>Vivziepop</li> <li>Felix Colgrave</li> <li>Chipflake</li> <li>James Lee</li> <li>sodikken</li> <li>Sim Gretina</li> <li>fooffle</li> <li>cuptoast</li> <li>sournoodl</li> <li>DeadlyComics</li> <li>The Musical Ghost</li> <li>tofuny</li> <li>Ekrixart</li> <li>lewvvk</li> <li>julian</li> <li>Hanzaki</li> <li>ANDY LAND</li> <li>Wozniakowski</li> <li>Kane Pixels</li> <li>squawkwardd</li> <li>saintlycharles</li> <li>tofuny</li> <li>Labirhin</li> </ul>"},{"location":"Lists/YT/#travel-vlog","title":"Travel / Vlog","text":"<ul> <li>shiey</li> <li>Vagrant Holiday</li> <li>VAGA VAGABOND</li> <li>The Wonton Don</li> </ul>"},{"location":"Lists/YT/#comedy-skit","title":"Comedy / Skit","text":"<ul> <li>Joel Haver</li> <li>Wizards with Guns</li> <li>Alternative Cuts</li> </ul>"},{"location":"Lists/YT/#gameplay-entertainment","title":"Gameplay / Entertainment","text":"<ul> <li>Videogamedunkey</li> <li>Sleep Deprived</li> </ul>"},{"location":"Lists/YT/#vfx","title":"VFX","text":"<ul> <li>Captain Disillusion</li> </ul>"},{"location":"Lists/YT/#misc","title":"Misc","text":"<ul> <li>Mikasacus</li> <li>Mattias Pilhede</li> <li>David Hoffman</li> <li>JREG</li> <li>jan Misali</li> <li>theweeklyslap</li> </ul>"},{"location":"Lists/YT/#see-also","title":"See Also","text":"<ul> <li>Japanese Learning</li> <li>Data Science / Statistics</li> </ul>"},{"location":"Lists/JLLR/","title":"Japanese Language Learning Resources","text":""},{"location":"Lists/JLLR/#grammar","title":"Grammar","text":"Guides  <ul> <li>Itazuraneko -&gt; alt 1 -&gt; alt 2</li> <li>Tatsumoto Ren -&gt; alt 1</li> <li>Japanese with Anime</li> <li>Ixrec's Guide to Japanese</li> <li>Tae Kim's Guide to Learning Japanese</li> <li>Organic Japanese</li> <li>boirodaisuki</li> <li>tofugu</li> <li>imabi</li> <li>sakubi</li> </ul>  Reference  <ul> <li>Core6000</li> <li>japbase</li> <li>nihongokyoshi</li> </ul>"},{"location":"Lists/JLLR/#sentence-mining","title":"Sentence Mining","text":"<ul> <li>TheMoeWay</li> <li>Immersion-Based Japanese Learning</li> <li>JP Lazy Guide</li> </ul>"},{"location":"Lists/JLLR/#books-manga-anime-etc","title":"Books, Manga, Anime, etc...","text":"<p>Most of these are NSFW so keep that in mind (for educational purposes only of course) </p> <ul> <li>yaoi-sei - BL</li> <li>aarinfantasy - BL</li> <li>Itazuraneko</li> <li>dl-raw</li> <li>rawlazy</li> <li>Bilingual Manga</li> <li>Manga Zip -&gt; alt</li> <li>syosetsu</li> <li>nyaa.si<ul> <li>sukubei (NSFW version of nyaa)</li> </ul> </li> </ul> <ul> <li>rawfree</li> <li>Alphapolis</li> <li>Dlraw</li> <li>rawkuma</li> <li>mangaz</li> <li>nhentai</li> <li>hitomi </li> <li>hentaiera</li> <li>hentai-one</li> <li>anime-sharing</li> </ul> Legal Sources <p>You have to pay to get manga from these websites, tofugu has a guide on how to do that. Sometimes these websites will also offer up some books/chapters for free (usually for a limited time) so it is also worth checking out even if you are not willing to spend some money.</p> <ul> <li>amazon.co.jp</li> <li>booklive</li> <li>cmoa</li> <li>ebookjapan</li> <li>DLsite</li> <li>Line Manga</li> <li>pixiv</li> </ul>"},{"location":"Lists/JLLR/#tools","title":"Tools","text":"Dictionary  <ul> <li>goo - discontinued</li> <li>jpdb</li> <li>weblio</li> <li>kotobank</li> </ul>  Character Extraction/Recogntion  <ul> <li>mokuro - manga OCR</li> <li>YomiNinja - screen OCR</li> <li>textractor - extract text from VNs</li> <li>yomitan - pop-up dictionary for browser</li> </ul>  Video Players  <p>asbplayer : A tool to add subtitles to online/streaming videos. The website jimaku is a good source of kanji subtitles for anime, etc..</p> Example sentence search <p>In google, twitter, etc.. Use quotation marks to surround a word/phrase to find examples of sentences containing them. Alternatively, the websites below are also useful</p> <ul> <li>immersionkit - examples from anime</li> <li>youglish - examples from YouTube</li> <li>sentencesearch</li> <li>massif.la</li> <li>kanshudo</li> <li>eijirou</li> </ul>"},{"location":"Lists/JLLR/#yt-channels","title":"YT Channels","text":"Education  <ul> <li>Moshi Moshi Yusuke</li> <li>Haru's Japanese Cafe</li> <li>Yohei Akiyama</li> <li>Kaname Naito</li> <li>Cure Dolly</li> <li>Maruhi Academy</li> <li>Scripting Japan</li> </ul>  Immersion  <p>There are way too many, so I decided to put them on a separate page.</p>"},{"location":"Lists/JLLR/Immersion/","title":"YT Channels for Immersion","text":""},{"location":"Lists/JLLR/Immersion/#bl-voice-comics","title":"BL Voice Comics","text":"<p>WHY ARE THERE SO MANY!! GAHH!</p> <ul> <li>BL sandwich</li> <li>BL skip</li> <li>BL kiss</li> <li>gyu BL</li> <li>CIEL BL</li> <li>After school</li> <li>moving BL</li> <li>KYOMUO</li> <li>Blooming magic</li> <li>BL diary</li> <li>bloomelow</li> <li>BoysASMR</li> </ul> <ul> <li>BL animal park</li> <li>iketen</li> <li>BL student council</li> <li>Mickymacky</li> <li>BL and Gente</li> <li>Gush and Emo</li> <li>Kajiyama</li> <li>Kadokawa</li> <li>Sankosha</li> <li>Cue Egg Label &amp; Melty Drop</li> <li>Nabarashoko</li> <li>BLove-ch</li> <li>Minakei</li> </ul>"},{"location":"Lists/JLLR/Immersion/#_1","title":"\u30a2\u30cb\u30e1\u30b3\u30f3\u30c8","text":"<p>\u30b3\u30f3\u30c8 means a short story, skit, comedy sketch, etc... It originates from the French word conte. Below are some \u30a2\u30cb\u30e1\u30b3\u30f3\u30c8 channels I enjoy, but there are loads more just search \"\u30a2\u30cb\u30e1\u30b3\u30f3\u30c8\" on YouTube to explore. </p> <ul> <li>HundredNote -&gt; Moved to a new channel<ul> <li>Snake Pit</li> <li>Hawk Eyes</li> <li>Swallow Tail</li> <li>Night Owl</li> </ul> </li> <li>karekoreya</li> <li>Kutsuzure Days</li> <li>Paranormal HS</li> </ul> <ul> <li>MariMariMari</li> <li>Pyutifi</li> <li>Lovelysomeday</li> <li>teipen</li> <li>tasukukoma</li> <li>fermilab</li> <li>rinlab</li> <li>Atashin'chi - no kanji subs, but has Eng subs</li> </ul>"},{"location":"Lists/JLLR/Immersion/#vtubers","title":"VTubers","text":"<p>A wide range of content including : gameplay, vlogs, challenges, etc.. Most of which will include kanji subtitles so they are easy to follow along. </p> STPR <ul> <li>sutopuri</li> <li>KnightA</li> <li>Meteorites</li> <li>amptak</li> </ul>  VOISING  <ul> <li>ireisu</li> <li>starpolar</li> <li>Chrono\u25b7\u25c0Reverse</li> </ul>  MEROPRO  <ul> <li>meropaka</li> <li>BOOM MENT</li> </ul>  Nijisanji  <ul> <li>ChroNoir</li> <li>ROFMAO</li> <li>Seitokai</li> </ul>  Others  <ul> <li>sixfonia</li> <li>kokubibi</li> <li>Atatakakunaru</li> </ul>  Utaite  <ul> <li>Amatsuki</li> <li>Ado</li> <li>Mafumafu</li> <li>Soraru</li> </ul> <p>VTuber clip channels are also a good source, just search up : <code>[Name of VTUBER] + \u5207\u308a\u629c\u304d / \u6587\u5b57\u8d77\u3053\u3057 / \u624b\u66f8\u304d</code> and you should be able to find some good stuff.</p>"},{"location":"Lists/JLLR/Immersion/#misc","title":"Misc","text":"<ul> <li>Sorami</li> <li>DALT</li> <li>Jiro Japanese</li> </ul>"},{"location":"blog/","title":"Blog","text":"<p>If I come across something cool and educational, I'll try to write about it over here. Each post is sorted into categories (check the about page).</p> <p>Warning</p> <p>I may make mistakes/inaccuracies here and there with what I say on here. If you notice one of these mistakes, I would appreciate it if you could let me know.</p>"},{"location":"blog/#recent-posts","title":"Recent Posts :","text":""},{"location":"blog/About/","title":"Categories","text":""},{"location":"blog/About/#maths","title":"Maths","text":"<p>Exactly what it says. Mostly, this will be a place where I can document and keep track of some ideas/concepts.</p>"},{"location":"blog/About/#data-science-statistics","title":"Data Science / Statistics","text":"<p>Exactly what it says. Mostly, this will be a place where I can document and keep track of some ideas/concepts.</p>"},{"location":"blog/About/#projects","title":"Projects","text":"<p>A place where I'll document some projects (mostly coding) that I have been working on.</p>"},{"location":"blog/About/#japanese","title":"Japanese","text":"<p>Mostly stuff about the language since I am learning it at the moment, but can be about some bits of culture/history that I find cool too.</p>"},{"location":"blog/About/#things-i-like-corner","title":"Things I Like Corner","text":"<p>A place where I'll share some of the stuff that I enjoy consuming. This includes, but is not limited to : cool YT videos, music, animation, anime, BL, character art, etc..</p>"},{"location":"blog/About/#miscellaneous","title":"Miscellaneous","text":"<p>Anything that does not fit into the above categories</p>"},{"location":"blog/2025/09/20/%E3%81%84%E3%83%BC%E3%81%82%E3%82%8B%E3%81%B5%E3%81%81%E3%82%93%E3%81%8F%E3%82%89%E3%81%B6-cantonese-version/","title":"\u3044\u30fc\u3042\u308b\u3075\u3041\u3093\u304f\u3089\u3076 (Cantonese version)","text":"<p>\u3044\u30fc\u3042\u308b\u3075\u3041\u3093\u304f\u3089\u3076 is a vocaloid song by mikitoP. The song itself is about learning Chinese, and so it has gained quite the popularity in China, to the point that chinese versions of the song have been made.</p> <p>Even cooler than that is the Cantonese version of the song by Hane (embedded above). The song is mainly in Cantonese, with some Chinese and Japanese, and a sentence of English, making it consist of 4 languages in total (very cool). I was rather upset that there weren't any lyrics available for this version of the song so I decided to transcribe it myself. I'm not confident enough to translate them to English, but you can use CC-Canto to check the meanings out and explore for yourself.</p>"},{"location":"blog/2025/09/20/%E3%81%84%E3%83%BC%E3%81%82%E3%82%8B%E3%81%B5%E3%81%81%E3%82%93%E3%81%8F%E3%82%89%E3%81%B6-cantonese-version/#lyrics","title":"Lyrics","text":"Original Text Romanization \u4e2d\u570b\u8857\u807d\u5230\u4e00\u8072\u4f60\u597d\u55ce zung1 gwok3 gaai1 teng1 dou2 jat1 sing1 nei5 hou2 maa1 \u8981\u600e\u7b54\u8a71 jiu3 zam2 daap3 waa6 \u65bc\u8ab2\u5ba4\u7540\u8db3\u5fc3\u6a5f\u5b78\u4ee5\u6f22\u8a9e\u8b1b\u8aaa\u8a71 jyu1 fo3 sat1 bei2 zuk1 sam1 gei1 hok6 ji5 hon3 jyu5 gong2 syut3 waa6 \u7576\u4f60\u60f3\u6253\u62db\u547c\u8981\u8b1b\u8072 dong1 nei5 soeng2 daa2 ziu1 fu1 jiu3 gong2 seng1 \u3053\u3093\u306b\u3061\u308f konnichiwa \u54ce\u5414\u5414\u73ed\u4e2d\u8acb\u8b1b\u4e2d\u6587(\u4f60\u597d) ai1 jaa3 jaa3 baan1 zung1 cing2 gong2 zung1 man4 (N\u01d0 h\u01ceo) \u8acb\u63ed\u958b\u300c\u7d66\u521d\u7d1a\u8005\u300d\u90a3\u4e00\u7248 cing2 kit3 hoi1\u300ckap1 co1 kap1 ze2\u300dnaa5 jat1 baan2 \u63ed\u597d\u4e86\u5427\uff1f kit3 hou2 liu5 baa6 \u5fc3\u88cf\u7684\u7f9e\u6065\u4e4b\u611f\u5b9a\u8981\u62fc\u52c1\u514b\u5236\u5427 sam1 leoi5 dik1 sau1 ci2 zi1 gam2 ding6 jiu3 ping3 ging6 haak1 zai3 baa1 \u4e0d\u8981\u4f7f\u7e73\u4ea4\u7684\u73ed\u8cbb\u7a7a\u82b1 bat1 jiu3 sai2 giu2 gaau1 dik1 baan1 fai3 hung1 faa1 \u662f\u6709\u9ede\u8cb4 si6 jau5 dim2 gwai3 \u597d\u5566\u597d\u5566\u4e00\u8d77\u8b1b(\u4f60\u597d\u5417) hou2 laa1 hou2 laa1 jat1 hei2 gong2 (N\u01d0 h\u01ceo ma) \u53eb\u300c\u5abd\u5abd\u300d\u8207\u300c\u99ac\u5339\u300d\u7684\u300c\u99ac\u300d giu3\u300cmaa1 maa1\u300djyu5\u300cmaa5 pat1\u300ddik1\u300cmaa5\u300d \u300c\u5abd\u300d\u300c\u99ac\u300d \u300cmaa1\u300d\u300cmaa5\u300d Who are you my friend? \u304d\u307f\u306f\u3060\u308c\uff1f Who are you my friend? kimi wa dare? \u4f60\u662f\u8ab0\u554a N\u01d0 sh\u00ec sh\u00e9i \u0101 \u6211\u60f3\u53ef\u4ee5\u5411\u8001\u5927\u529b\u5b8f\u8aaa\u8a71 ngo5 soeng2 ho2 ji5 hoeng3 lou5 daai6 lik6 wang4 syut3 waa6 \u4ee5\u6f22\u8a9e\u8aaa\u53e5\u592a\u611b\u6155\u4f60\u5566 ji5 hon3 jyu5 syut3 geoi3 taai3 ngoi3 mou6 nei5 laa1 \u30cf\u30a4\u30cf\u30a4\u30c1\u30e3\u30a4\u30ca\u6578\u6578\u300c\u4e00\u300d\u300c\u4e8c\u300d\u4e5f\u597d\u73a9 hai hai chaina sou3 sou3\u300cjat1\u300d\u300cji6\u300djaa5 hou2 waan2 \u756a\u85af\u6703\u8207\u7c89\u7d72\u5403\u98ef faan1 syu2 wui5 jyu5 fan2 si1 hek3 faan6 \u373a\u373a\u78ba\u5f88\u373a\u6f22\u8a9e\u6a02\u5712\u7121\u9650\u7480\u71e6 zaan2 zaan2 kok3 han2 zaan2 hon3 jyu5 lok6 jyun4 mou4 haan6 ceoi1 caan3 \u6211\u71b1\u60c5\u5f85\u76fc(\u6211\u7231\u4f60)\u935b\u934a\u5f9e\u672a\u61f6 ngo5 jit6 cing4 doi6 paan3 (W\u01d2 \u00e0i n\u01d0) dyun3 lin6 cung4 mei6 laan5 (\u4f60\u597d)\u3001\u4f60\u597d\u3001\u3053\u3093\u306b\u3061\u308f N\u01d0 h\u01ceo nei5 hou2 konnichiwa \u8a8d\u771f\u5572 jing6 zan1 di1 \u5413\uff1f\u5481... \u3060\u308c (\u4f60\u662f\u8ab0) \u4f60\u4fc2\u4e5c\u6c34 haa5 ? gam2 ... dare, (n\u01d0 sh\u00ec she\u00ed) nei5 hai6 mat1 seoi2 \u5582\u6559\u5572\u65e5\u5e38\u7528\u5572\u5605\u597d\u5187... wai3 gaau3 di1 jat6 soeng4 jung6 di1 ge3 hou2 mou5 ... \u5413, \u8b1b\u5462\u5572 haa5, gong2 ni1 di1 \u958b\u59cb\u5566 hoi1 ci2 laa1 \u4e2d\u570b\u8857\u525b\u525b\u8b58\u5230\u5973\u9ad8\u4e2d\u751f zung1 gwok3 gaai1 gong1 gong1 sik1 dou2 neoi5 gou1 zung1 sang1 \u307f\u304b\u3061\u3083\u3093 mika-chan \u5979\u544a\u77e5 taa1 gou3 zi1 \u5468\u8463\u5bf6\u5cf6\u5c31\u5feb\u6703\u6709\u6f14\u5531\u5427 zau1 dung2 bou2 dou2 zau6 faai3 wui5 jau5 jin2 coeng3 baa1 \u6240\u4ee5\u5462\u4e0d\u807d\u4e0d\u53ef\u5662\u5566\u5566 so2 ji5 ne1 bat1 teng1 bat1 ho2 ou3 laa1 laa1 \u7f8e\u4f73\u54aa\u4f4f mei5 gaai1 mai6 zyu6 \u591a\u9ebc\u53ef\u60dc\u5bf6\u5cf6\u7b49\u65bc\u570b\u5916\u5834\u662f\u5427 do1 mo1 ho2 sik1 bou2 dou2 dang2 jyu1 gwok3 ngoi6 coeng4 si6 baa1 \u4e0d\u8981\u6025\u6469\u6253\u8acb\u4f60\u95dc\u95dc bat1 jiu3 gap1 mo1 daa2 cing2 nei5 gwaan1 gwaan1 \u30df\u30ab\u3061\u3083\u3093 mika-chan \u53ef\u4ee5\u627e\u597d\u5fc3\u53f8\u6a5f\u9806\u52e2\u8f09\u5ba2\u4e00\u8d77\u4e0a\u8def ho2 ji5 zaau2 hou2 sam1 si1 gei1 seon6 sai3 zoi3 haak3 jat1 hei2 soeng5 lou6 \u9019\u8d9f\u9808\u82b1\u591a\u5c11\u8981\u6578\u6578 ze2 tong3 seoi1 faa1 do1 siu2 jiu3 sou3 sou3 \u662f\u6709\u9ede\u8cb4 si6 jau5 dim2 gwai3 \u5fc5\u9808\u6253\u5de5\u627e\u6563\u5de5\u52aa\u529b\u505a bit1 seoi1 daa2 gung1 zaau2 saan2 gung1 nou5 lik6 zou6 \u3059\u307f\u307e\u305b\u3093\u304a\u3058\u3087\u3046\u3055\u3093(\u5c0f\u59d0) sumimasen oj\u014dsan (siu2 ze2) \u3053\u308c\u4e00\u3064\u3044\u304f\u3089\u3067\u3057\u3087\u3046(\u591a\u5c11\u94b1\u554a) kore hitotsu ikura desho (du\u014d sh\u01ceo qi\u00e1n a) \u76fc\u8ddf\u5929\u570b\u88cf\u54e5\u54e5\u570b\u69ae\u8aaa\u8a71 paan3 gan1 tin1 gwok3 leoi5 go1 go1 gwok3 wing4 syut3 waa6 \u4f86\u4ee5\u6f22\u8a9e\u8aaa\u53e5\u7f8e\u5922\u665a\u5b89 loi4 ji5 hon3 jyu5 syut3 geoi3 mei5 mung6 maan5 on1 \u30cf\u30a4\u30cf\u30a4\u30c1\u30e3\u30a4\u30ca\u6578\u6578\u300c\u4e00\u300d\u300c\u4e8c\u300d\u4e5f\u597d\u73a9 hai hai chaina sou3 sou3\u300cjat1\u300d\u300cji6\u300djaa5 hou2 waan2 \u756a\u85af\u6703\u8207\u7c89\u7d72\u5403\u98ef faan1 syu2 wui5 jyu5 fan2 si1 hek3 faan6 \u373a\u373a\u78ba\u5f88\u373a\u6f22\u8a9e\u6a02\u5712\u7121\u9650\u7480\u71e6 zaan2 zaan2 kok3 han2 zaan2 hon3 jyu5 lok6 jyun4 mou4 haan6 ceoi1 caan3 \u6211\u71b1\u60c5\u5f85\u76fc ngo5 jit6 cing4 doi6 paan3 \u5922\u4e2d\u76fc\u60f3\u7740\u65bc\u6211\u5fc3\u88cf\u591a\u96c0\u8e8d mung6 zung1 paan3 soeng2 zoek6 jyu1 ngo5 sam1 leoi5 do1 zoek3 joek6 \u6642\u9593\u9077\u4eba\u4e16\u8f49\u8208\u596e\u611f\u89ba\u4e0d\u8b8a\u5f31 si4 gaan3 cin1 jan4 sai3 zyun2 hing1 fan5 gam2 gok3 bat1 bin3 joek6 \u5118\u7ba1\u6709\u9ede\u50cf\u6eba\u9032\u865b\u64ec\u9019\u6d77\u6d0b zeon2 gun2 jau5 dim2 zoeng6 nik1 zeon3 heoi1 ji5 ze2 hoi2 joeng4 \u751c\u5922\u4e5f\u7121\u8fa6\u6cd5\u80fd\u9000\u8b93 tim4 mung6 jaa5 mou5 baan6 faat3 nang4 teoi3 joeng6 \u30cf\u30a4\u30cf\u30a4\u30c1\u30e3\u30a4\u30ca\u3061\u3087\u3061\u3087\u5922\u5fc3\u5730 hai hai chaina cho cho yumegokochi \u3044\u30fc\u3042\u308b\u30d5\u30a1\u30f3\u30af\u30e9\u30d6 i-aru fankurabu \u3060\u3093\u3060\u3093\u541b\u3068\u540c\u3058\u8a00\u8449\u304c\u4f7f\u3048\u308b\u306d dan dan kimi to onaji kotoba ga tsukaerune \u30cf\u30a4\u30cf\u30a4\u30c1\u30e3\u30a4\u30ca hai hai chaina \u5929\u5929\u5f35\u671b\u3044\u3061\u3070\u3093 tin1 tin1 zoeng1 mong6 ichiban \u756a\u85af\u6703\u8207\u7c89\u7d72\u5403\u98ef faan1 syu2 wui5 jyu5 fan2 si1 hek3 faan6 \u373a\u373a\u78ba\u5f88\u373a\u4ee5\u6f22\u8a9e\u8b1b\u51fa\u6211\u71b1\u611b zaan2 zaan2 kok3 han2 zaan2 ji5 hon3 jyu5 gong2 ceot1 ngo5 jit6 ngoi3 \u52aa\u529b\u80fd\u7372\u8b9a nou5 lik6 nang4 wok6 zaan3 \u6211\u7231\u4f60 w\u01d2 \u00e0i n\u01d0 \u8aaa\u8457\u80fd\u7fd2\u6163 syut3 zoek6 nang4 zaap6 gwaan3 \u3044\u30fc\u3042\u308b\u30d5\u30a1\u30f3\u30af\u30e9\u30d6 i-aru fankurabu \u6211\u7231\u4f60\u80fd\u5426\u544a\u8a34\u4f60 w\u01d2 \u00e0i n\u01d0 n\u00e9ng f\u01d2u g\u00e0o s\u00f9 n\u01d0 \u6211\u7231\u4f60(\u6211\u7231\u4f60) w\u01d2 \u00e0i n\u01d0 (ngo5 ngoi3 nei5)"},{"location":"blog/2025/09/21/inner-product-space-rightarrow-topology/","title":"Inner Product Space $\\Rightarrow$ Topology","text":"<p>This post outlines how an inner product space can be given a canonical topological structure. I will assume that you know some basic knowledge about fields and vector/metric/topological spaces.</p>"},{"location":"blog/2025/09/21/inner-product-space-rightarrow-topology/#inner-products","title":"Inner Products","text":"<p>Definition 1. Let \\(V\\) be a vector space over the field \\(\\mathbb{R}\\). A (real) inner product is any function \\(\\langle \\cdot, \\cdot \\rangle : V\\times V\\to \\mathbb{R}\\) satisting : for all \\(x,y,z\\in V\\) and \\(a,b\\in \\mathbb{R}\\),</p> <ul> <li><p> \\(\\langle x,y \\rangle = \\langle y,x\\rangle\\)          Symmetry      </p></li> <li><p> \\(\\langle ax + by, z \\rangle = a \\langle x,z \\rangle + b\\langle y,z \\rangle\\)          Linearity      </p></li> <li><p> \\(x\\neq 0 \\ \\Longrightarrow \\ \\langle x,x \\rangle &gt; 0\\)          Positive-definiteness      </p></li> </ul> <p>We shall say : \"Let \\(V\\) be a (real) inner product space\" to mean that \\(V\\) is a vector space over \\(\\mathbb{R}\\) that is equipped with a (real) inner product.</p> <p>Additional (quickfire) properties of (real) inner product spaces :</p> <p>It is easy to see that linearity is equivalent to the following two, simpler conditions :</p> <ul> <li>\\(\\langle ax,z \\rangle = a \\langle x,z\\rangle\\)</li> <li>\\(\\langle x+y,z \\rangle = \\langle x,z \\rangle + \\langle y,z \\rangle\\)</li> </ul> <p>Combining symmetry and linearity, we obtain linearity in the second argument :</p> <ul> <li>\\(\\langle x, ay+bz \\rangle = a \\langle x,y \\rangle + b\\langle x,z \\rangle\\)</li> </ul> <p>By using linearity twice to break down the inner product :</p> <ul> <li>\\(\\langle x+y, x+y \\rangle = \\langle x,x\\rangle + 2\\langle x,y\\rangle + \\langle y,y\\rangle\\)</li> </ul> <p>By setting \\(a:=0\\) in \\(\\langle ax,z \\rangle = a \\langle x,z\\rangle\\) and using symmetry we get :</p> <ul> <li>\\(\\langle 0,z \\rangle = \\langle z,0 \\rangle = 0\\)</li> </ul> <p>In particular :</p> <ul> <li>\\(\\langle x,x \\rangle = 0 \\iff x=0\\)</li> </ul> <p>Proof. The backwards direction is immediate. The contrapositive of the forwards direction : \\(x\\neq 0 \\Rightarrow \\langle x,x \\rangle \\neq 0\\) is a direct consequence of positive-definiteness.</p> <p>As a corollary :</p> <ul> <li>\\(\\langle x,x \\rangle \\geq 0\\) for all \\(x\\in V\\) with equality if and only if \\(x=0\\).</li> </ul>"},{"location":"blog/2025/09/21/inner-product-space-rightarrow-topology/#complex-inner-product-space","title":"Complex Inner Product Space?","text":"<p>We emphasize \"real\" because inner products can also be defined over a complex vector space (a vector space \\(V\\) over \\(\\mathbb{C}\\)). In particular, a complex inner product is a function \\(\\langle \\cdot, \\cdot \\rangle: V\\times V\\to \\mathbb{C}\\) satisfying a slightly different set of properties. A complex inner product space is a complex vector space equipped with a complex inner product. While both real and complex inner product spaces are largely equal in terms of their behavior, there are some differences here and there. </p> <p>$\\quad \\ $ From now on, any mention of vector/inner product spaces shall specifically refer to their real versions.</p>"},{"location":"blog/2025/09/21/inner-product-space-rightarrow-topology/#norms","title":"Norms","text":"<p>Definition 2. In an inner product space, the \"norm\" of a vector \\(x\\in V\\) is defined as the real number \\(\\sqrt{\\langle x,x \\rangle}\\) and is denoted \\(\\Vert x \\Vert\\). Note that \\(\\langle x,x\\rangle\\) is always non-negative so we don't have to worry about negative values in the square root.</p> <p>It is easy to check (apart from the last property) that the norm satisfies the following properties : for all \\(x\\in V\\) and \\(a\\in \\mathbb{R}\\),</p> <ul> <li><p> \\(\\Vert x \\Vert \\geq 0\\)          Non-negativity      </p></li> <li><p> \\(\\Vert x \\Vert = 0 \\ \\iff x=0\\)          Positive-definiteness      </p></li> <li><p> \\(\\Vert ax \\Vert = |a|\\Vert x \\Vert\\)          Absolute homogeneity      </p></li> <li><p> \\(\\lVert x+y \\rVert \\leq \\lVert x\\rVert + \\lVert y\\rVert\\)          Triangle inequality      </p></li> </ul> <p>Proving the triangle inequality is not straightforward and some prior machinery is needed, namely we would first have to prove the Cauchy-Schwarz inequality.</p>"},{"location":"blog/2025/09/21/inner-product-space-rightarrow-topology/#the-cauchy-schwartz-inequality","title":"The Cauchy-Schwartz Inequality","text":"<p>Lemma 1. In an inner product space, for any \\(x,y\\in V\\)</p> \\[ \\langle w,w\\rangle = \\langle x,x\\rangle\\left(\\langle x,x\\rangle \\langle y,y\\rangle - \\langle x,y\\rangle^2\\right) \\] <p>where \\(w:= \\langle x,y\\rangle x - \\langle x,x\\rangle y\\).</p> Proof <p>By direct computation \\(\\langle w,w\\rangle\\) expands (and then simplifies) to :</p> \\[ \\langle x,x\\rangle^2 \\langle y,y\\rangle - \\langle x,y\\rangle^2 \\langle x,x\\rangle  \\] <p>Factoring \\(\\langle x,x\\rangle\\) out :</p> \\[ \\langle x,x\\rangle \\left(\\langle x,x\\rangle \\langle y,y\\rangle - \\langle x,y\\rangle^2\\right) \\] <p>as needed.</p> <p>Theorem 1.1 (Cauchy-Schwartz Inequality). In an inner product space, for any vectors \\(x,y\\in V\\) we have</p> \\[ \\langle x,y\\rangle^2 \\leq \\langle x,x\\rangle \\langle y,y\\rangle \\] Proof <p>In the case that \\(x=0\\) then the result is trivial, thus we may suppose that \\(x\\neq 0\\).</p> <p>By Lemma 1, </p> \\[ 0\\leq \\langle w,w\\rangle = \\langle x,x\\rangle\\left(\\langle x,x\\rangle \\langle y,y\\rangle - \\langle x,y\\rangle^2\\right) \\] <p>Since \\(x\\neq 0\\) we must have \\(\\langle x,x\\rangle &gt; 0\\). Thus \\(\\langle x,x\\rangle \\langle y,y\\rangle - \\langle x,y\\rangle^2\\) has to be non-negative for the above to hold, but then</p> \\[ \\langle x,y\\rangle^2 \\leq \\langle x,x\\rangle \\langle y,y\\rangle \\] <p>as needed. </p> <p>By taking the positive square-root in the CS inequality, we obtain the following equivalent form :</p> \\[ |\\langle x,y\\rangle| \\leq \\Vert x\\Vert \\Vert y\\Vert \\] <p>The next theorem answers what it exactly means when 2 vectors achieve equality in the CS inequality :</p> <p>Theorem 1.2 (Cauchy-Schwartz Inequality). In an inner product space, for any vectors \\(x,y\\in V\\) the following are equivalent :</p> <ol> <li>\\(\\langle x,y\\rangle^2 = \\langle x,x\\rangle \\langle y,y\\rangle\\)</li> <li>\\(x=0\\) OR \\(y=\\frac{\\langle x,y\\rangle}{\\langle x,x\\rangle}x\\)</li> <li>\\(x=0\\) OR there exists a scalar \\(k\\in \\mathbb{R}\\) such that \\(y=kx\\)</li> </ol> <p>\\((2)\\to (3)\\) is obvious. As for the rest :</p> Proof. \\((1)\\to (2)\\) <p>We shall instead prove that \\(x\\neq 0\\) implies \\(y=\\frac{\\langle x,y\\rangle}{\\langle x,x\\rangle}x\\). By Lemma 1 : </p> \\[ \\langle w,w\\rangle = \\langle x,x\\rangle(\\langle x,x\\rangle \\langle y,y\\rangle - \\langle x,y\\rangle^2) \\] <p>but (1) implies that \\(\\langle w,w\\rangle = 0\\) which implies that \\(w=0\\) which means \\(\\langle x,y \\rangle x = \\langle x,x\\rangle y\\). It suffices to divide both sides by \\(\\langle x,x\\rangle\\), noting that we are allowed to do so since \\(x\\neq 0\\) by assumption.</p> Proof. \\((3)\\to (1)\\) <p>If \\(x=0\\) then (1) is obvious. Otherwise, On the LHS : </p> \\[\\langle x,y\\rangle^2 = \\langle x, kx\\rangle^2 = k^2\\langle x,x\\rangle^2 \\] <p>On the RHS :</p> \\[ \\langle x,x\\rangle \\langle y,y\\rangle = \\langle x,x\\rangle \\langle kx,kx\\rangle = k^2\\langle x,x\\rangle^2\\] <p>Thus both sides are equal as needed.</p>"},{"location":"blog/2025/09/21/inner-product-space-rightarrow-topology/#triangle-inequality","title":"Triangle Inequality","text":"<p>With the CS inequality, proving the triangle inequality is simple :</p> \\[ \\begin{align*}     \\Vert x+y \\Vert^2 &amp;= \\Vert x\\Vert^2 + \\Vert y\\Vert^2 + 2\\langle x,y\\rangle \\\\     &amp;\\leq \\Vert x\\Vert^2 + \\Vert y\\Vert^2 + 2|\\langle x,y\\rangle| \\\\     &amp;\\leq \\Vert x\\Vert^2 + \\Vert y\\Vert^2 + 2\\Vert x\\Vert \\Vert y\\Vert \\\\     &amp;= (\\Vert x\\Vert +\\Vert y\\Vert)^2 \\end{align*} \\] <p>Definition 3. Given a vector space \\(V\\), a norm refers to any function \\(\\Vert \\cdot \\Vert : V\\to \\mathbb{R}\\) satisfying the 4 properties listed shortly after Definition 2. A vector space equipped with a norm is known as a normed space.</p> <p>What we have shown is that in any inner product space, \\(\\Vert x\\Vert := \\sqrt{\\langle x,x\\rangle}\\) defines a norm. In other words, an inner product space can (if necessary) be considered as a normed space (by equipping it with the norm defined above).</p>"},{"location":"blog/2025/09/21/inner-product-space-rightarrow-topology/#norm-to-metric","title":"Norm to Metric","text":"<p>Roughly speaking, a metric space is a space in which a notion of distance is defined, that is to say there is a way to take two points of the space and spit out an \\(r\\in \\mathbb{R}\\) that represents the distance between them in a way that makes sense.</p> <p>There is a way to define a notion of distance in a normed space by setting the distance between two points as \\(\\Vert x-y\\Vert\\). For this to make sense we will have to prove, for all \\(x,y,z\\in V\\) that :</p> <ul> <li>\\(\\Vert x-x\\Vert =0\\)  The distance between two points is zero </li> <li>\\(x\\neq y \\Longrightarrow \\Vert x-y\\Vert &gt;0\\)  Positivity </li> <li>\\(\\Vert x-y\\Vert = \\Vert y-x\\Vert\\)  Symmetry  </li> <li>\\(\\Vert x-z\\Vert \\leq \\Vert x-y\\Vert + \\Vert y-z\\Vert\\)  Triangle Inequality V2 </li> </ul> <p>Properties 1-3 are easy to show. Triangle inequality V2 is just a reformulation of the original triangle inequality :</p> \\[ \\Vert x-z \\Vert = \\Vert (x-y) + (y-z) \\Vert \\leq \\Vert x-y \\Vert + \\Vert y-z \\Vert \\]"},{"location":"blog/2025/09/21/inner-product-space-rightarrow-topology/#metric-space-to-topology","title":"Metric Space to Topology","text":"<p>Definition 4. In a metric space \\(X\\) we define the open ball with center \\(p\\in X\\) and radius \\(r\\in \\mathbb{R}\\) to be the subset containing all points \\(x\\in X\\) such that \\(d(x,p)&lt;r\\). We write \\(B(p,r) := \\{x\\in X \\ | \\ d(x,p)&lt;r\\}\\) to denote this subset.</p> <p>Definition 5. In a metric space \\(X\\), a subset \\(A\\subseteq X\\) is said to be open iff for every \\(x\\in A\\) there exists a strictly positive \\(r\\in \\mathbb{R}\\) such that \\(B(x,r)\\subseteq A\\). </p> <p>To equip a set with a topology it suffices to specify which subsets are open (which we have already done) and then prove that the collection of open subsets satisfy the necessary topological properties : </p> <p>Theorem 2. Let \\(\\tau\\) denote the collection of open subsets in a metric space \\(X\\), then :</p> <ul> <li>\\(\\varnothing, X \\in \\tau\\)</li> <li>For any \\(S\\subseteq \\tau, \\ \\bigcup S \\in \\tau\\)</li> <li>For any finite \\(S\\subseteq \\ \\tau, \\bigcap S\\in \\tau\\)</li> </ul> Proof <ul> <li> <p>For the first property, note that \\(\\varnothing\\) is trivially open. Similarly, \\(X\\) is open because for every \\(p\\in X\\) we obviously have \\(B(p,1)\\subseteq X\\).</p> </li> <li> <p>For the second property, suppose that \\(x\\in \\bigcup S\\), then \\(x\\in A\\) for some \\(A\\in S\\). Thus \\(A\\) is open so there exists an \\(r&gt;0\\) such that \\(B(x,r)\\subseteq A\\subseteq \\bigcup S\\) so we are done.</p> </li> <li> <p>For the third property, suppose that \\(x\\in \\bigcap S\\), i.e. \\(x\\in A\\) for every \\(A\\in S\\). Each \\(A\\) is open and since \\(S\\) is finite, we obtain a finite list of radii \\(r_1,r_2,\\ldots,r_n&gt;0\\). Let \\(r_m\\) be the minimum of these radii, then \\(B(r_m)\\subseteq B(r_i)\\subseteq A_i\\) for all \\(i=1,2,\\ldots,n\\). Thus \\(B(r_m)\\subseteq \\bigcap S\\) as needed.</p> </li> </ul>"},{"location":"blog/2025/09/21/inner-product-space-rightarrow-topology/#an-inner-product-on-mathbbrn","title":"An Inner Product on \\(\\mathbb{R}^n\\)","text":"<p>To \"naturally\" give the vector space \\(\\mathbb{R}^n\\) a topology, it suffices to equip it with a \"natural\" inner product, which naturally defines a norm, which naturally defines a distance, which naturally defines a topology.</p> <p>Let \\(x= (x_1,x_2,\\ldots,x_n)\\) and \\(y=(y_1,y_2,\\ldots y_n)\\). We define the inner product \\(\\langle x,y\\rangle := \\sum_{i=1}^n x_iy_i\\) and declare this to be the natural/default inner product on \\(\\mathbb{R}^n\\). Of course, we would first have to prove that symmetry, linearity, and positive-definiteness are satisfied. </p> Proof <p>Both symmetry and positive-definiteness are obvious. For linearity, we show first that \\(\\langle ax,y\\rangle =a\\langle x,y\\rangle\\) and then \\(\\langle x+y,z\\rangle = \\langle x,z\\rangle + \\langle y,z\\rangle\\). The former is obvious. As for the latter :</p> \\[ x+y=(x_1+y_1,x_2+y_2,\\ldots x_n+y_n)\\] <p>so that </p> \\[\\langle x+y,z\\rangle = \\sum_{i=1}^n x_iz_i+y_iz_i = \\sum_{i=1}^n x_iz_i + \\sum_{i=1}^n y_iz_i = \\langle x,z\\rangle + \\langle y,z\\rangle \\] <p>Specializing the CS inequality to the inner product on \\(\\mathbb{R}^n\\) we get the following inequality for free:</p> \\[ \\left|\\sum_{i=1}^n x_iy_i\\right| \\leq \\sqrt{\\sum_{i=1}^nx_i^2}\\sqrt{\\sum_{i=1}^ny_i^2} \\] <p>for any \\(x_1,x_2,\\ldots,x_n,y_1,y_2,\\ldots,y_n\\in \\mathbb{R}\\).</p>"},{"location":"blog/2025/10/01/%E8%90%BD%E8%AA%9E-rakugo/","title":"\u843d\u8a9e (Rakugo)","text":"<p>Rakugo (\u843d\u8a9e) is a form of Japanese verbal comedy where a lone storyteller kneels on a raised platform while telling a story (often comedic in nature) to a public audience<sup>1</sup>. What I want to talk about today are twofold : One, the etymology behind rakugo, and two, how this relatively ancient form of entertainment has seeped its way into pop culture.</p> Rakugo in action. An image just to help you visualize what it is supposed to look like."},{"location":"blog/2025/10/01/%E8%90%BD%E8%AA%9E-rakugo/#etymology","title":"Etymology","text":"<p>Rakugo is made up of the kanji \u843d and \u8a9e, the latter meaning \"word\", \"language\", or \"speech\" and is hence self-explanatory. What is more interesting is the appearance of the kanji \u843d. It is commonly seen in the verb pair \u843d\u3061\u308b\u30fb\u843d\u3068\u3059, meaning \"to drop\". It is not immediately clear how \"drop\" could possibly be related to \"comedic storytelling\". In fact, when I first heard of the word \"rakugo\", I thought for sure that it would be written as \u697d\u8a9e, where the former kanji, \u697d, means \"happiness\", \"comfort\", etc...</p> <p>It turns out that \u843d\u3061 (ochi), the noun form of the verbs \u843d\u3061\u308b\u30fb\u843d\u3068\u3059, can be translated as \"punchline\" in English. In other words, \u697d\u8a9e literally means \"story with a punchline\". How \"drop\" and \"punchline\" are related, I don't know. I tried searching for sources that would explain this, but I couldn't find much beyond some blogs<sup>2</sup> and forums<sup>3</sup> which gave conflicting answers anyways. My idea is that \"punchline\" -&gt; \"outcome/conclusion\" -&gt; \"drop\", i.e. the punchline is where the story \"drops\" itself. Maybe it's not even correct to attempt rationalizing this from an English language perspective, but whatever.</p>"},{"location":"blog/2025/10/01/%E8%90%BD%E8%AA%9E-rakugo/#pop-culture","title":"Pop Culture","text":""},{"location":"blog/2025/10/01/%E8%90%BD%E8%AA%9E-rakugo/#jugemu","title":"Jugemu (\u5bff\u9650\u7121)","text":"<p>The most famous rakugo story in terms of its appearance in pop culture is probably Jugemu (\u5bff\u9650\u7121). The comedic part of the story comes from the repetition of a character's (Jugemu's) ridiculously long full name : </p> Jugemu's full name : <p>Jugemu Jugemu (\u5bff\u9650\u7121 \u5bff\u9650\u7121) Gok\u014d-no Surikire (\u4e94\u52ab\u306e\u64e6\u308a\u5207\u308c) Kaijarisuigyo-no (\u6d77\u7802\u5229\u6c34\u9b5a\u306e) Suigy\u014dmatsu Unraimatsu F\u016braimatsu (\u6c34\u884c\u672b \u96f2\u6765\u672b \u98a8\u6765\u672b) Kuunerutokoro-ni Sumutokoro (\u98df\u3046\u5bdd\u308b\u51e6\u306b\u4f4f\u3080\u51e6) Yaburak\u014dji-no Burak\u014dji (\u3084\u3076\u3089\u67d1\u5b50\u306e\u3076\u3089\u67d1\u5b50) Paipopaipo Paipo-no Sh\u016bringan (\u30d1\u30a4\u30dd\u30d1\u30a4\u30dd \u30d1\u30a4\u30dd\u306e\u30b7\u30e5\u30fc\u30ea\u30f3\u30ac\u30f3) Sh\u016bringan-no G\u016brindai (\u30b7\u30e5\u30fc\u30ea\u30f3\u30ac\u30f3\u306e\u30b0\u30fc\u30ea\u30f3\u30c0\u30a4) G\u016brindai-no Ponpokop\u012b-no Ponpokon\u0101-no (\u30b0\u30fc\u30ea\u30f3\u30c0\u30a4\u306e\u30dd\u30f3\u30dd\u30b3\u30d4\u30fc\u306e\u30dd\u30f3\u30dd\u30b3\u30ca\u30fc\u306e) Ch\u014dky\u016bmei-no Ch\u014dsuke (\u9577\u4e45\u547d\u306e\u9577\u52a9)</p> <p>Jugemu has been referenced numerous of times in modern media, most notably by the anime Fullmetal Alchemist : Brotherhood in their 4-koma theater :</p> <p>Another appearance is as the ending song in the anime Joshiraku :</p> <p>which currently has over 56 million views. If you've got a keen eye then you'll notice as well that Joshi (\u5973\u5b50) Raku (\u843d) is an anime about girls doing rakugo (I swear there's an anime about anything these days). There is also a reference by Gintama and there have also been memes/skits made based on Jugemu. If your Japanese is good enough, you may find this parody of Jugemu entertaining as well.</p> <p>For this reason, Jugemu and its references in media are probably most people's (myself included) first introduction into the world of rakugo. Unfortunately, at the time I did not go so far as to look into this topic beyond \"oh, so this is something Japanese people do\" and so, for a long time afterwards I stopped thinking about rakugo... that is until I encountered, rather recently, another rakugo reference in media..</p>"},{"location":"blog/2025/10/01/%E8%90%BD%E8%AA%9E-rakugo/#shinigami","title":"Shinigami (\u6b7b\u795e)","text":"<p>Shinigami (\u6b7b\u795e) is another famous rakugo story. \u6b7b\u795e basically means \"the God of death\", which we probably know better by the name \"Grim Reaper\". You can hear the full story on YouTube (English subtitles included). How I got to know shinigami is through the song by the same name by Kenshi Yonezu which is themed around the rakugo story :</p> <p>I ended up listening to shinigami (the rakugo story) because I was interested in the phrase \"Ajaraka mokuren tekerettsu no paa!\"  that was used in the song. In the story, it turns out that this phrase is uttered (like a spell) to chase the shinigami away. Of course, I tried digging deeper and found a nice blogpost which explains how this phrase came about :</p> <p>Apparently, this \"spell\" was added for comedic effects since there was concern with the story being too dark and not going over well with the audience<sup>4</sup>. The \"spell\" however is not completely gibberish. The \"mokuren\" part is based on the name of one of Buddha's closest disciple, Maudgaly\u0101yana. In Japanese, the name is pronounced Mokuren/Mokukenren (\u76ee\u728d\u9023). The \"Ajaraka\" part is based on the word \"acharya\" (\u963f\u95cd\u68a8) which is an honorific used for Buddhist high monks. The rest of the spell is probably gibberish; \"Ajaraka mokuren tekerettsu no paa!\" is basically calling on the spirit of Maudgaly\u0101yana, then making some noises to scare the shinigami away.</p> <p>Finally, I would just like to add that I am currently watching Shouwa Genroku Rakugo Shinjuu (another anime about rakugo) and I am enjoying it so far. The first episode is basically a freaking movie and I was happy to hear \"Ajaraka mokuren tekerettsu no paa!\" within the first minute and immediately understanding the reference.</p> <ol> <li> <p>https://en.wikipedia.org/wiki/Rakugo \u21a9</p> </li> <li> <p>https://note.com/akaoka/n/nd540e83b6f4b \u21a9</p> </li> <li> <p>https://detail.chiebukuro.yahoo.co.jp/qa/question_detail/q13269577393 \u21a9</p> </li> <li> <p>https://brahmus.seesaa.net/article/500043036.html \u21a9</p> </li> </ol>"},{"location":"blog/2025/09/15/%E6%96%AF%E3%80%85%E7%84%B6%E3%80%85/","title":"\u65af\u3005\u7136\u3005","text":"<p>I came across an interesting-sounding word while watching episode 8 of Youkai Gakkou no Sensei Hajimemashita! :</p> <p>The anime was even kind enough to provide an explanation, and I thought that was funny.</p>"},{"location":"blog/2025/09/15/%E6%96%AF%E3%80%85%E7%84%B6%E3%80%85/#usage","title":"Usage","text":"<p>\u65af\u3005\u7136\u3005 (\u304b\u304f\u304b\u304f\u3057\u304b\u3058\u304b) is often used in media as a practical phrase that an author can use in place of some long explanation that the reader/viewer might already be aware of. For example, imagine the following situation :</p> <ul> <li>Scene 1 : Something happens to character A</li> <li>Scene 2 : Character B shows up and asks what happened</li> <li>Scene 3 : Character A explains the situation</li> </ul> <p>Now, the author may make \"Character A\" go through the whole song and dance of explaining the situation (which the readers most likely don't want), or they may simply make \"Character A\" say something like\u300c\u307e\u3041\u3002\u3002\u304b\u304f\u304b\u304f\u3057\u304b\u3058\u304b\u3067\u3053\u3046\u306a\u3061\u3083\u3063\u305f\u300d</p> <p>It can also be used (though I am not sure how commonly) in real-life conversations. For example, you can use it whenever you want to explain yourself without revealing any details. Here are some examples<sup>1</sup> :</p> <ul> <li>\u65af\u3005\u7136\u3005\u3042\u308a\u307e\u3057\u3066\u2026\u96e2\u5a5a\u3059\u308b\u4e8b\u306b\u306a\u308a\u307e\u3057\u305f\u3002</li> <li>\u65af\u3005\u7136\u3005\u306e\u4e8b\u60c5\u304c\u3042\u3063\u3066\u3001\u9000\u8077\u3059\u308b\u4e8b\u306b\u306a\u3063\u305f\u3002</li> <li>\u65af\u3005\u7136\u3005\u3042\u3063\u3066\u3001\u9045\u308c\u3061\u3083\u3063\u305f\u306e\u3002\u3054\u3081\u3093\u306d\u3002</li> </ul> <p>The fact that the anime felt the need to explain what this phrase meant seems to suggest that it is not often used in everyday life.</p>"},{"location":"blog/2025/09/15/%E6%96%AF%E3%80%85%E7%84%B6%E3%80%85/#pop-culture","title":"Pop Culture","text":"<p>\u304b\u304f\u304b\u304f\u3057\u304b\u3058\u304b has been used as a title for a certain manga. It is also the name of a deer mascot character used by Daihatsu for advertisments and such. This is probably a pun, \\(\\stackrel{\\tiny \u3057\u304b}{\\footnotesize \u9e7f}\\) being the kanji for deer.</p>"},{"location":"blog/2025/09/15/%E6%96%AF%E3%80%85%E7%84%B6%E3%80%85/#history","title":"History","text":"<p>In the anime, it was also mentioned that \u304b\u304f\u304b\u304f\u3057\u304b\u3058\u304b was used in the \u4e07\u8449\u96c6 (Man'y\u014dsh\u016b), an 8th century anthology of Japanese poetry. Both \u304b\u304f\u304b\u304f and \u3057\u304b\u3058\u304b are archaic ways of saying \u3053\u3046\u3060/\u3053\u306e\u3088\u3046\u306b<sup>2</sup> and so it seems that people of the time decided to combine them to create the \u304b\u304f\u304b\u304f\u3057\u304b\u3058\u304b that we know of today. It is one of the few phrases from Old Japanese to have persisted all the way to the modern age.</p>"},{"location":"blog/2025/09/15/%E6%96%AF%E3%80%85%E7%84%B6%E3%80%85/#reference","title":"Reference :","text":"<ol> <li> <p> https://ja.hinative.com/questions/19937586  \u21a9</p> </li> <li> <p> https://www.tbs.co.jp/kodomotel/etc/0088.html  \u21a9</p> </li> <li> <p>https://d.hatena.ne.jp/keyword/\u304b\u304f\u304b\u304f\u3057\u304b\u3058\u304b \u21a9</p> </li> <li> <p> https://dic.pixiv.net/a/\u304b\u304f\u304b\u304f\u3057\u304b\u3058\u304b  \u21a9</p> </li> </ol>"},{"location":"blog/2025/09/22/the-pillbug-incident/","title":"The Pillbug Incident","text":""},{"location":"blog/2025/09/22/the-pillbug-incident/#what-is-a-pillbug","title":"What is a pillbug?","text":"<p>For those who do not know (because I sure as hell didn't), the \"pill bug\" is a common name given to the Armadillidiidae family of woodlice. The pill bug has the ability to roll into a ball, earning them the alternative (perhaps more familiar) name : roly-polies. </p> <p></p> <p>An image of a pill bug! Sorry if I grossed you out. You've probably seen or played with these as a kid, or hey... maybe I'm the only weird one here.</p> <p>Despite now being aware of what a pillbug is, I'm sure that you guys are no closer to knowing what \"The Pillbug Incident\" could possibly be referring to, but I am going to need you guys to be a bit more patient as I talk about a seemingly unrelated topic.</p>"},{"location":"blog/2025/09/22/the-pillbug-incident/#weathernews-live","title":"Weathernews LiVE","text":"<p>Weathernews LiVE (WNL) is a private Japanese weather report channel which primarily broadcasts through the internet (as opposed to the television, because I know some of you guys forgot those exist). For example, they sometimes broadcast live and upload clips of their broadcasts on their YouTube channel. </p> <p>WNL is massively popular for simply being a weather report channel, some of their clips have garnered more than 10 million views. Part of the reason why is because WNL's weather reporters are almost exclusively cute, young, females. WNL understands that the audience are watching for the personalities behind the screen as opposed to the weather news itself, and they lean into this by organizing fan meetup events, selling merchandise, etc.. Basically, these weatherwomen are being seen and treated the same way as any other idol. Japanalysis made a great video on this topic, criticizing the normalization of this type of culture. Fortunately, this hotbed of a topic is not something we'll be delving towards; although the context may be helpful. </p>"},{"location":"blog/2025/09/22/the-pillbug-incident/#the-pillbug-incident","title":"The Pillbug Incident","text":"<p>One of the most famous WNL clips (over 18 million views at the time of writing) is the \"\u30c0\u30f3\u30b4\u30e0\u30b7\u4e8b\u4ef6\" (pillbug incident), a blooper where the weather caster Rinon Ohshima (\u5927\u5cf6\u7483\u97f3) mistakenly refers to her colleague, the meteorologist Yamaguchi Takehisa (\u5c71\u53e3\u525b\u592e), as a \"pillbug\", leading to a funny exchange :   </p> <p>The only reason I thought to write about this \"incident\" is because this blooper is a great way to learn about Japanese particles. Afterall, the cause of Ohshima's unfortunate blunder is the result of an incorrect particle usage. </p>"},{"location":"blog/2025/09/22/the-pillbug-incident/#clip-analysis","title":"Clip analysis","text":""},{"location":"blog/2025/09/22/the-pillbug-incident/#part-1-the-context","title":"Part 1 : The Context","text":"<p> Click to play segment (0:00-0:07)  <pre><code>\u5927\u5cf6 : \u4eca\u65e5\u306f\u7d50\u69cb\u6c17\u6e29\u6771\u4eac\u4e0a\u304c\u308a\u307e\u3057\u305f\u3051\u3069\u3082\u30c0\u30f3\u30b4\u30e0\u30b7\u306f\u307e\u3060\u4eca\u65e5\u306f\u898b\u5f53\u305f\u3089\u306a\u304b\u3063\u305f\u3067\u3059\u304b\uff1f\n\u5c71\u53e3 : \u4eca\u65e5\u306f\u51fa\u306a\u304b\u3063\u305f\u3067\u3059\u3002\n</code></pre></p> <p>The conversation that will eventually lead to the infamous \"Pillbug Incident\". Ohshima started by asking Yamaguchi if he was able to find any pillbugs today despite it getting hotter (in Tokyo), to which Yamaguchi replied that he wasn't able to, and the conversation continued on from there.</p> <p>To understand this bit of dialogue, you will need two pieces of context :</p> <p>Context 1</p> <p>The appearance of pillbugs is known to correlate with different weather conditions. For example, pillbugs prefer to live in cool, dark, and moist environments<sup>3</sup>, so you are more likely to see them during or after it rains.</p> <p>Context 2</p> <p>Yamaguchi is well known to be a data enthusiast, personally collecting all sorts of data ranging from insect activity to natural disasters<sup>4</sup>. Ohshima asked if Yamaguchi was able to find any pillbugs today with this in mind. </p>"},{"location":"blog/2025/09/22/the-pillbug-incident/#part-2-the-incident","title":"Part 2 : The Incident","text":"<p> Click to play segment (0:08-0:13) </p> <pre><code>\u5927\u5cf6 : \u3055\u3042\u3001\u3068\u3044\u3046\u3053\u3068\u3067\u30c0\u30f3\u30b4\u30e0\u30b7\u306b\u3082\u306d\u3001\u89e3\u8aac\u3057\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f\u3051\u3069\u3002\n</code></pre> <p>\"Well, with that said, we've received an explanation from a pillbug as well...\", said Ohshima, indirectly referring to Yamaguchi as a \u30c0\u30f3\u30b4\u30e0\u30b7 (pillbug in Japanese). Ohshima's blunder stems from mistakenly marking \u30c0\u30f3\u30b4\u30e0\u30b7 with the particle \u306b\u3082. </p> <p>In most cases, including this one, \u306b\u3082 can be thought of as the particles \u306b and \u3082 operating separately<sup>1</sup>. That is to say, \u30c0\u30f3\u30b4\u30e0\u30b7 is marked twice, once by \u306b and the second time by \u3082. Marking an object with the particle \u3082 gives it a sense of \"also\", \"another\", \"yet again\", etc... For example :</p> <pre><code>\u300c\u79c1\u3082\u308a\u3093\u3054\u304c\u597d\u304d\u300d: I too like apples \n\u300c\u308a\u3093\u3054\u3082\u3059\u304d\u300d: I like apples too\n</code></pre> <p>In the first case \u79c1 (I/me) is marked by \u3082. You are proclaiming yourself as an (additional) member of the \"apple-liker\" group. You would say this when your friends are talking about how much they love apples, and you want to include yourself as a part of that. In the second case \u308a\u3093\u3054 (apple) is marked. You are proclaiming that apples, perhaps in addition to bananas, mangos, etc... are also a member of the \"fruits-I-like\" group.</p> <p>The particle \u306b is more complex as it has many functions (7, according to the DOJG). In this specific instance \u306b acts as :</p> <p>From the Dictionary of Japanese Grammar (DOJG)<sup>5</sup> : </p> <p>\"A particle that indicates an agent or a source in passive, causative, \u3082\u3089\u3046/\u3066\u307e\u3089\u3046 and other receiving constructions\"</p> <p>Isolating the key parts of Ohshima's sentence, we get</p> <pre><code>\u5927\u5cf6 : [\u30c0\u30f3\u30b4\u30e0\u30b7] [\u306b\u3082] [\u89e3\u8aac\u3057\u3066] [\u3044\u305f\u3060\u304d\u307e\u3057\u305f]\n</code></pre> <p>\u3044\u305f\u3060\u304d\u307e\u3057\u305f is the past tense of the verb \u3044\u305f\u3060\u304f, which means \"to recieve\". You've probably heard the phrase \u3044\u305f\u3060\u304d\u307e\u3059 being used before eating a meal. In the context of a meal this basically means : \"I shall humbly receive/accept the food that is in front of me\". </p> <p>Note</p> <p>\u3044\u305f\u3060\u304f is no different to \u3082\u3089\u3046 apart from being more polite (it is the \u8b19\u8b72\u8a9e of \u3082\u3089\u3046)</p> <p>A verb can be attached to \u3044\u305f\u3060\u304f via its \u3066-form to indicate the receival of an action. For example :</p> <p><code>\u89e3\u8aac\u3059\u308b (to explain) $\\to$ \u89e3\u8aac\u3057\u3066 + \u3044\u305f\u3060\u304d\u307e\u3057\u305f (received an explanation)</code></p> <p>As discussed, \u306b marks the agent/source of the action (\u89e3\u8aac\u3059\u308b) that is being received. Thus :</p> <p><code>\u30c0\u30f3\u30b4\u30e0\u30b7\u306b(\u3082)\u89e3\u8aac\u3057\u3066\u3044\u305f\u304d\u307e\u3057\u305f : (also) received an explanation from a pillbug</code></p> <p>\u30c0\u30f3\u30b4\u30e0\u30b7 being marked with \u3082 indicates that the pillbug is part of a larger collection of things that you have received explanations from, or alternatively that the explanation from a pillbug is part of a larger series of events that happened. The second interpretation is probably more likely.</p> <p>And so that concludes the explanation behind the grammatical mishap that took the attention of more than 18 million people, the pillbug incident. </p>"},{"location":"blog/2025/09/22/the-pillbug-incident/#part-3-wait-theres-more","title":"Part 3 : Wait? There's More?","text":"<p>What? You think we're done with learning about particles? We're just getting started. Yamaguchi was quick to correct Ohshima's mistake :</p> <p> Click to play segment (0:13-0:18)  <pre><code>\u5c71\u53e3 : \u30c0\u30f3\u30b4\u30e0\u30b7\u201d\u306e\u201d\u3067\u3059\u3088\u306d\uff1f\n\u5927\u5cf6 : \u3042\u3001\u30c0\u30f3\u30b4\u30e0\u30b7\u201d\u306e\u201d\u3002\u3002\u3002\n\u5c71\u53e3 : \u79c1\u3001\u30c0\u30f3\u30b4\u30e0\u30b7\u3067\u306f\u306a\u3044\u3002\u3002\u3002\n</code></pre></p> <p>\"You probably meant to say \u300c\u30c0\u30f3\u30b4\u30e0\u30b7\u306e\u300d (instead of \u306b\u3082) right?\", asked Yamaguchi, understandably in disbelief after having just been referred to as a pillbug lol. The \u306e-corrected sentence is then :</p> <pre><code>\u30c0\u30f3\u30b4\u30e0\u30b7\u306e\u89e3\u8aac\u3057\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f\n</code></pre> <p>At first glance, it appears that we have a <code>Noun + \u306e + Verb</code> pattern, which strays away from the typical <code>Noun + \u306e + Noun</code> that we are used to. After searching around for a bit, I have found at least one case (probably the only case) in which this construction is possible : In attributive clauses, \u306e marks the agent performing an action that serves as an attribute of something else<sup>2</sup>. </p> <p>For example :</p> <pre><code>\u96ea\u306e\u964d\u308b\u591c : A snowy night\n\u30ab\u30ca\u30a8\u306e\u4f5c\u3063\u305f\u30cd\u30c3\u30af\u30ec\u30b9 : The necklace that Kanae made\n</code></pre> <p>The pattern is : <code>Noun1 + \u306e + Verb + Noun2</code>, where <code>Noun1</code> is the performer of <code>Verb</code> and this serves as an attribute for <code>Noun2</code>. However <code>\u30c0\u30f3\u30b4\u30e0\u30b7\u306e\u89e3\u8aac\u3057\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f</code> does not have a <code>Noun2</code>. Does this mean that the \u306e-corrected sentence is ungrammatical? Surely Yamaguchi's correction to Ohshima's grammar mistake can't yet again be another grammar mistake?!</p> <p>What we have overlooked is to understand that \u89e3\u8aac\u3059\u308b is a noun that has been \"verbified\" by the addition of \u3059\u308b. That is to say \u89e3\u8aac is the noun \"explanation\" while \u89e3\u8aac\u3059\u308b is the verb \"to explain\". The idea is to treat\u300c\u30c0\u30f3\u30b4\u30e0\u30b7\u306e\u89e3\u8aac\u300das the noun \"explanation about pillbugs\" and observe that the addition of \u3059\u308b turns it into the verb \"to explain about pillbugs\". </p> <p>Putting it all togther, \u30c0\u30f3\u30b4\u30e0\u30b7\u306e\u89e3\u8aac\u3057\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f means \"(I) received an explanation about pillpugs\" which was probably what Ohshima meant to say.</p>"},{"location":"blog/2025/09/22/the-pillbug-incident/#part-4-another-correction","title":"Part 4 : Another Correction","text":"<p> Click to play segment (0:23-0:37)  <pre><code>\u5927\u5cf6 : \u9055\u3046\u9055\u3046\u3002\u5c71\u53e3\u3055\u3093\u3001\u9055\u3044\u307e\u3059\u3088\u3002\n   : \u5c71\u53e3\u3055\u3093\u3001\u30c0\u30f3\u30b4\u30e0\u30b7\"\u3082\"\u89e3\u8aac\u3057\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f\u3051\u3069\u3063\u3066\u3002\n   : \u8a00\u304a\u3046\u3068\u601d\u3063\u305f\u3093\u3067\u3059\u3051\u3069\u3082\u3002\u79c1\u304c\u3061\u3087\u3063\u3068\u8272\u3005\u9593\u9055\u3048\u307e\u3057\u3066\u3002\n</code></pre></p> <p>Ohshima reveals that she had intended to say \u300c\u30c0\u30f3\u30b4\u30e0\u30b7\u3082\u89e3\u8aac\u3057\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f\u300d but a rougue \"\u306b\" has slipped in by accident.</p> <p>We've already mentioned that a \u3082-marked object is given a sense of \"also\", \"another\", \"in addition\", etc... This means that we can interpret the intended sentence as : \"Pillbugs (among other things), I received an explanation\". </p> <p>With regards to how the rougue \"\u306b\" slipped in, Ohshima was probably thinking about saying :</p> <pre><code>\u30c0\u30f3\u30b4\u30e0\u30b7(\u306b\u3064\u3044\u3066)\u3082\u89e3\u8aac\u3044\u305f\u3060\u304d\u307e\u3057\u305f\n</code></pre> <p>Which can be interpreted as \"About pillbugs (among other things), I received an explanation\", \u300c\u306b\u3064\u3044\u3066\u300d meaning \"about\", \"with regards to\", etc... Ohshima then probably forgot to say the \u3064\u3044\u3066 part of \u306b\u3064\u3044\u3066.</p>"},{"location":"blog/2025/09/22/the-pillbug-incident/#references","title":"References","text":"<ol> <li> <p>https://selftaughtjapanese.com/2020/06/22/japanese-particle-combination-\u306b\u3082-ni-mo/ \u21a9</p> </li> <li> <p>https://imabi.org/the-particle-\u306e-ii/ \u21a9</p> </li> <li> <p>https://knowledge.carolina.com/discipline/life-science/pill-bug-behavior-choices/ \u21a9</p> </li> <li> <p>https://dic.pixiv.net/a/\u30c0\u30f3\u30b4\u30e0\u30b7\u306b\u3082\u89e3\u8aac\u3057\u3066\u3044\u305f\u3060\u304d\u307e\u3057\u305f \u21a9</p> </li> <li> <p>https://core6000.neocities.org/dojg/entries/100 \u21a9</p> </li> </ol>"},{"location":"blog/2025/09/21/about-sequences/","title":"About Sequences..","text":""},{"location":"blog/2025/09/21/about-sequences/#introduction","title":"Introduction","text":"<p>A sequence in some space \\(X\\) is usually represented by some function \\(a:\\mathbb{N}\\to X\\) so that the first term of the sequence is \\(a(1)\\), the second is \\(a(2)\\) and so on. However, we usually write \\(a_n\\) in place of \\(a(n)\\) for aesthethic reasons.</p> <p>Given a sequence \\(a\\) of points in \\(X\\), an interesting question to ask is whether or not this sequence converges to some \\(L\\in X\\). In order for this question to make sense there has to be some notion of distance on the space \\(X\\), which we can do by specifying a metric (or more generally a topology) on \\(X\\). </p> <p>Very briefly, a metric on \\(X\\) is a function \\(d:X\\times X\\to \\mathbb{R}\\) that can be used as some sort of \"ruler\" on \\(X\\); for any \\(x,y\\in X\\) the real number \\(d(x,y)\\) represents how far away these two points are from each other, the smaller \\(d(x,y)\\) is the closer \\(x\\) and \\(y\\) are and vice-versa. </p> <p>Warning</p> <p>Of course, a metric has to \"make sense\". For example, we cannot have \\(d(x,x)=2\\), or \\(d(x,y)&lt;0\\), and so on. There is a list of properties that a function \\(d:X\\times X\\to \\mathbb{R}\\) has to satisfy in order for it to \"make sense\" to be used as a metric. For example \\(d(x,y):= |x-y|\\) is an example of a function that makes sense to be used as a metric on the space \\(\\mathbb{R}\\). I won't get into all of the details here since it suffices to just have an intuitive idea; you can of course look into it at your own time.</p>"},{"location":"blog/2025/09/21/about-sequences/#eventual-behavior-of-a-sequence","title":"Eventual Behavior of a Sequence","text":"<p>Intuitively speaking, convergence is an eventual behavior of a sequence. For example, if \\(a\\to L\\) then any modification of \\(a\\) that does not alter its eventual behavior (for example, removing the first 100 terms) will not affect its convergence. To be more specific, a sequence \\(a\\) eventually satisfies some property \\(P\\) if there is some index \\(N\\in \\mathbb{N}\\) such that \\(P\\) is satisfied by \\(a_N, a_{N+1}, a_{N+2}, \\ldots\\) </p> <p>Example</p> <p>Let \\(P\\) be the property \"is equal to 1\". Then the sequence </p> \\[ 5,4,3,2,1,1,1,1,\\ldots \\] <p>eventually satisfies \\(P\\) since \\(a_n = 1\\) for all \\(n\\geq 5\\).</p> <p>Instead of talking about properties, we can talk about subsets. To say that a sequence \\(a\\) of points in \\(\\mathbb{N}\\) is \"eventually equal to 1\" or \"is eventually even\" amounts to saying that \\(a\\) will eventually be contained in the subsets \\(\\{1\\}\\) or \\(\\{2n \\ \\vert \\ n\\in \\mathbb{N}\\}\\) respectively. In other words, there is a 1-to-1 correspondence between a property on some space \\(X\\) and its subsets. Thus, we may simplify things by declaring that the only property we should concern ourselves with is that of containment in some subset :</p> <p>Definition 1. A sequence \\(a\\) on some space \\(X\\) is said to be eventually contained in some subset \\(A\\subseteq X\\) if there exists an \\(N\\in \\mathbb{N}\\) such that \\(a_n\\in A\\) for all \\(n\\geq N\\).</p> <p>If we can find some \\(N\\in \\mathbb{N}\\) for which \\(a_n\\in A\\) for all \\(n\\geq N\\), then the number of indices \\(m\\) for which \\(a_m \\notin A\\) cannot be greater than \\(N-1\\). In other words there are only a finite number of, we shall say \"bad\" indices. On the other hand, if there are only a finite number of bad indices, then there has to be the largest \"bad\" index, which we'll call \\(M\\). This implies that \\(a_n\\in A\\) whenever \\(n\\geq M+1\\), i.e. we have shown that \\(a\\) is eventually contained in \\(A\\). In conclusion, the \"eventual behavior\" of a sequence can be reframed via the finiteness of its set of bad indices.</p> <p>Recall that a sequence is really just a function \\(a:\\mathbb{N}\\to X\\). Thus, the set of bad indices can be expressed in terms of the inverse image : \\(a^{-1}[A^c]\\). Similarly, the set of \"good indices\" can be represented by \\(a^{-1}[A]\\). Clearly, taking the complement of the good indices gives us the bad indices (and vice-versa). This gives us the following identity :</p> \\[ a^{-1}[A]^c = a^{-1}[A^c] \\] <p>In other words, the inverse image of a complement is a complement of the inverse image, which is true in general. We will use this concept to define yet another way to reframe \"eventual behavior\" : Instead of checking to see if the set of bad indices is finite, we can try to check to see if the set of good indices is \"large enough\". </p> <p>Notice that having an infinite number of elements is not a sufficient condition for a set to be \"large enough\". For example, if the good indices are : \\(2,4,6,8,\\ldots\\) then this implies the existence of an infinite number of bad indices, namely \\(1,3,5,7,\\ldots\\) Thus, we need a stronger condition for \"large enough\". Consider the following :</p> <p>Definition 2. Let \\(A\\) be some subset of a space \\(X\\). We say that \\(A\\) is cofinite if \\(A^c := X\\setminus A\\) is finite. Let \\(Fr\\) be the collection of all cofinite subsets of \\(\\mathbb{N}\\), we call \\(Fr\\) the Fr\u00e9chet filter.</p> <p>By construction, cofinite sets are indeed \"large enough\" for our needs, i.e. it becomes trivial that : the set of bad indices is finite iff the set of good indices is cofinite (is contained in the Fr\u00e9chet filter). Thus, whenever I say that a sequence \\(a\\) is eventually contained in \\(A\\), it can mean either of the following conditions :</p> <ul> <li>There exists an \\(N\\in \\mathbb{N}\\) such that \\(a_n\\in A\\) for \\(n\\geq N\\)</li> <li>The set of bad indices is finite : \\(a^{-1}[A^c]\\) is finite</li> <li>The set of good indices is cofinite : \\(a^{-1}[A]\\in Fr\\)</li> </ul> <p>Afterall, we have shown that all three are equivalent.  </p>"},{"location":"blog/2025/09/21/about-sequences/#convergence-as-an-eventual-behavior","title":"Convergence as an Eventual Behavior","text":"<p>Definition 3. For any \\(\\epsilon&gt;0\\) and \\(L\\in X\\) we define \\(B_\\epsilon(L):=\\{x\\in X \\ \\vert \\ d(L,x)&lt;\\epsilon\\}\\). This can be thought of as the collection of points that are close to \\(L\\). Thinking of \\(\\epsilon&gt;0\\) as a parameter, we can control exactly how close the points in \\(B_\\epsilon(L)\\) are to \\(L\\).  </p> <p>Example</p> <p>In the space \\(\\mathbb{R}\\) with the metric \\(d(x,y):=|x-y|\\), the set \\(B_1(0)\\) is exactly the open interval \\((-1,1)\\).</p> <p>Fix some \\(L\\in X\\). It makes sense to say that a sequence \\(a\\to L\\) if it is eventually contained in \\(B_\\epsilon(L)\\) where \\(\\epsilon&gt;0\\) can be controlled to specify the desired level of \"closeness\". For example, to say that \\(a\\) is eventually contained in \\(B_1(L)\\) means that the terms of \\(a\\) will eventually be at a distance of at most 1 away from \\(L\\). With this in mind, we come up with the following definition :</p> <p>Definition 4. A sequence \\(a\\) on some metric space \\(X\\) is said to converge to some \\(L\\in X\\) if for any \\(\\epsilon&gt;0\\), \\(a\\) is eventually contained in \\(B_\\epsilon(L)\\)</p> <p>Exercise 1</p> <p>Let \\(a\\) be a sequence in \\(X\\), \\(A\\) be a subset of \\(X\\) and \\(f:\\mathbb{N}\\to \\mathbb{N}\\) be an injection. Show that if \\(a\\) is eventually contained in \\(A\\), then the sequence \\(a\\circ f\\) is also eventually contained in \\(A\\). By extension, this means that whenever \\(a\\to L\\) we also have \\(a\\circ f \\to L\\). I recommend using the finiteness of the bad indices for this proof.</p> Answer <p>A key lemma which we won't prove here : </p> <p> For any injection \\(f:X\\to Y\\) and \\(A\\subseteq Y\\) we have \\(|f^{-1}[A]| \\leq |A|\\) </p> <p>Now for the actual proof : Our goal is to show that \\([a\\circ f]^{-1}[A^c]\\) is finite. Let \\(B := [a\\circ f]^{-1}[A^c]\\). Notice that </p> \\[B = f^{-1}[a^{-1}[A^c]]\\] <p>By definition, the set \\(a^{-1}[A^c]\\) is finite. By our lemma, \\(B\\) has to be finite as well so we are done. </p>"},{"location":"blog/2025/09/21/about-sequences/#pushforward","title":"Pushforward","text":"<p>This section builds up the theory needed to generalize the exercise above.</p> <p>Definition 5. A function \\(f:\\mathbb{N}\\to\\mathbb{N}\\) is said to be a pushforward if </p> \\[\\forall A\\subseteq \\mathbb{N}, \\ A\\in Fr \\Rightarrow f^{-1}[A]\\in Fr \\tag{1}\\] <p>Note</p> <p>For those that are familiar with topology, this looks awfully similar to the definition of a continuous function. In fact, the definitions match when we consider the space \\(\\mathbb{N}\\) with the cofinite topology. Alas I am not knowledgeable enough to quote on why this connection exists.</p> <p>In other words, a pushforward is a function whose inverse image preserves the largeness (co-finiteness) of a subset of \\(\\mathbb{N}\\). For example, the identity function is a trivial example of a pushforward.</p> <p>Let \\(a:\\mathbb{N}\\to X\\) be a sequence and \\(f:\\mathbb{N}\\to\\mathbb{N}\\) be a pushforward, then we can define a new sequence by composition : \\(a\\circ f\\). Here is a nice theorem about sequences constructed in such a manner :</p> <p>Theorem 2. Let \\(a:\\mathbb{N}\\to X\\) be a sequence and \\(f:\\mathbb{N}\\to \\mathbb{N}\\) be a pushforward. If \\(a\\) is eventually contained in some subset \\(A\\subseteq X\\) then so will \\(a\\circ f\\). By extension, whenever \\(a\\to L\\) we must also have \\(a\\circ f \\to L\\).</p> Proof <p>What we want to show is that \\(a^{-1}[A]\\in Fr\\) implies \\([a\\circ f]^{-1}[A]\\in Fr\\). First, assume that \\(a^{-1}[A]\\in Fr\\). Now notice that \\([a\\circ f]^{-1}[A] = f^{-1}[a^{-1}[A]]\\) and combine this with our assumption and the fact that \\(f\\) is a pushforward.</p> <p>I chose the name \"pushforward\" because the eventual behavior of \\(a\\) gets pushed forward into the new sequence \\(a\\circ f\\). Another characterization of pushforwards can be obtained by noticing that the condition \\((1)\\) is equivalent to :</p>  $\\forall \\ A\\subseteq \\mathbb{N}$, $ \\ A$ is finite $\\quad \\Longrightarrow \\quad$ $f^{-1}[A]$ is finite (2) <p>Proving this is not too hard once you recall that for any \\(f:X\\to Y\\) and \\(A\\subseteq Y\\) we have \\((f^{-1}[A])^c =  f^{-1}[A^c]\\). Another equivalent condition is :</p>  $\\forall m\\in \\mathbb{N}$, $ \\ f^{-1}[\\{m\\}]$ is finite (3) <p>The relevant hint here is that inverse images distribute under unions : \\(f^{-1}[A\\cup B] = f^{-1}[A] \\cup f^{-1}[B]\\). Finally, we have another equivalent condition :</p>  The sequence $f(n)$ diverges to $\\infty$ (4) <p>To prove this, I would suggest using the contrapositive, i.e. to show that \\(\\neg(3)\\to \\neg(4)\\) and that \\(\\neg(4)\\to \\neg(3)\\), but I will leave it up to you to fill in the details.</p> <p>Example</p> <p>We now know (by Exercise 1) that any injection \\(f:\\mathbb{N}\\to \\mathbb{N}\\) is also a pushforward. By definition, if \\(b\\) is a subsequence of \\(a\\) then \\(b = a\\circ f\\) for some strictly increasing \\(f:\\mathbb{N}\\to \\mathbb{N}\\). Clearly \\(f\\) is injective and hence a pushforward. Thus we may conclude that whenever \\(a\\to L\\) we also have \\(b = a\\circ f \\to L\\). We may also use the same argument to show that rearrangements of \\(a\\) preserves the original limit (if it exists).</p>"},{"location":"blog/2025/09/21/about-sequences/#pullback","title":"Pullback","text":"<p>We now turn our attention to the dual concept : pullbacks.</p> <p>Definition 7. A function \\(f:\\mathbb{N}\\to \\mathbb{N}\\) is said to be a pullback if</p> \\[\\forall A\\subseteq \\mathbb{N}, \\ f^{-1}[A] \\in Fr \\Longrightarrow A\\in Fr \\tag{5}\\] <p>Naturally, we have the corresponding theorem for \"pullback sequences\"</p> <p>Theorem 3. Let \\(a:\\mathbb{N}\\to X\\) be a sequence and \\(f:\\mathbb{N}\\to \\mathbb{N}\\) be a pullback. If \\(a\\circ f\\) is eventually contained in some subset \\(A\\subseteq X\\) then so will \\(a\\). By extension, whenever \\(a\\circ f\\to L\\) we must also have \\(a \\to L\\).</p> <p>The proof is similar and follows the same logic. An easy way to check if \\(f\\) is a pullback is to check if its image is cofinite :</p> <p>Theorem 4. A function \\(f:\\mathbb{N}\\to \\mathbb{N}\\) is a pullback iff \\(Im(f)\\in Fr\\).</p> Proof <p>We start with the forward direction. Setting \\(A:=Im(f)\\) in \\((5)\\) we notice that it suffices to show that \\(f^{-1}[Im(f)]\\) is cofinite. However, notice that</p> \\[ f^{-1}[Im(f)] := \\{x\\in \\mathbb{N} \\ \\vert \\ f(x)\\in Im(f)\\} = \\mathbb{N}\\] <p>which is obviously cofinite. For the reverse direction, let \\(A\\subseteq \\mathbb{N}\\) be arbitrary. We make the assumptions : \\(Im(f)\\in Fr\\) and \\(f^{-1}[A]\\in Fr\\). Our goal is to show that \\(A\\in Fr\\), i.e. that \\(A^c\\) is finite. First notice that \\(A^c\\) can be decomposed into two disjoint parts based on whether or not its elements are in \\(Im(f)\\) : </p> \\[ A^c = \\underbrace{\\left(A^c \\cap Im(F)\\right)}_{\\text{Part 1}} \\cup \\underbrace{\\left(A^c \\setminus Im(F)\\right)}_{\\text{Part 2}}\\] <p>Thus, it suffices to show that each part is finite. For part 2, notice that \\(A^c \\setminus Im(F) = A^c \\cap Im(f)^c\\subseteq Im(f)^c\\) which is finite by assumption so we are done. For Part 1 the following identities will prove useful :</p> <p>For any \\(f:X\\to Y\\) and any \\(A\\subseteq Y\\) :</p> \\[A \\cap Im(f) = f[f^{-1}[A]], \\quad \\quad f^{-1}[A^c] = f^{-1}[A]^c\\] <p>Now notice :</p> \\[ A^c \\cap Im(F) = f[f^{-1}[A^c]] = f[f^{-1}[A]^c] \\] <p>Recall that \\(f^{-1}[A]^c\\) is finite by assumption, thus Part 1 is the image of a finite set. The image of a finite set has still to be finite so we are done.</p> <p>Example</p> <p>Let \\(f(n) := n+100\\). Then \\(f\\) is a pullback since \\(Im(f)\\in Fr\\). Suppose you were asked to show that \\((a_1, a_2, \\ldots)\\) converges to \\(L\\), then you could (if for some reason it is easier) prove that \\((a_{101}, a_{102},\\ldots)\\to L\\) instead, and pull that property back into the original sequence.</p>"},{"location":"blog/2025/09/21/about-sequences/#appendix","title":"Appendix","text":""},{"location":"blog/2025/09/21/about-sequences/#stich-sequences","title":"Stich Sequences","text":"<p>Say we are given three sequences \\(a,b,c\\) of points in some space \\(X\\). We can stitch these sequences together to create a new sequence \\(\\times(a,b,c)\\) of points in \\(X\\) defined by :</p> \\[ \\times(a,b,c) := a_1, b_1, c_1, a_2, b_2, c_2, a_3, \\ldots \\] <p>Of course we can stitch together any finite number of sequences together, as long as they map to the same space of course. </p> <p>Exercise 2</p> <p>If each individual sequence is eventually contained in some subset \\(A\\subseteq X\\) then would the stitched sequence also be eventually contained in \\(A\\)? How about vice-versa? Try to figure this out on your own before looking at the answer :</p> Answer <p>The reverse direction is easy to prove since we can take a subsequence of the stitched sequence to reconstruct any of its original components. We can then do a pushforward to transfer this property into each of the component sequences. </p> <p>For the forward direction, we can notice that the number of bad indices of the stitched sequence can be obtained by summing up the bad indices of each component sequence. By assumption, each component has a finite number of bad indices and since there are only finitely many components the stitched sequence should also have a finite number of bad indices.</p> <p>Here is a cool example of using stitch sequences in practice :</p> <p>Theorem 5. Let \\(f_1, f_2,\\ldots f_k : \\mathbb{N}\\to \\mathbb{N}\\) be a finite collection of functions such that \\(\\bigcup_{i=1}^k Im(f_i)\\in Fr\\). Suppose we have a sequence \\(a:\\mathbb{N}\\to X\\). For any \\(A\\subseteq X\\), if each \\(a\\circ f_i\\) is eventually contained in \\(A\\), then so will \\(a\\). By extension, if each \\(a\\circ f_i \\to L\\) then it is also the case that \\(a\\to L\\). </p> Proof <p>Consider the stitched sequence :</p> \\[ s := \\times(a\\circ f_1, a\\circ f_2, \\ldots, a\\circ f_k) \\] <p>We know that \\(s\\) is eventually contained in \\(A\\). It should also be clear that there is a function \\(F:\\mathbb{N}\\to \\mathbb{N}\\) such that \\(s = a\\circ F\\). Thus, to prove our goal it suffices to show that \\(F\\) is a pullback. Notice that \\(Im(F) = \\bigcup_{i=1}^k Im(f_i)\\). By assumption \\(Im(F)\\in Fr\\), thus by Theorem 4 \\(F\\) is a pullback.</p>"},{"location":"blog/2025/09/21/about-sequences/#a-note-on-divergence","title":"A Note on Divergence","text":"<p>If there is no point \\(L\\in X\\) for which \\(a\\to L\\) then we say that \\(a\\) is divergent. In the space \\(\\mathbb{R}\\), there are three ways in which a sequence can diverge : either \\(a\\to \\infty\\), \\(a\\to -\\infty\\), or \\(a\\) oscillates around. Just like how convergence can be viewed as an eventual behavior, divergence to \\(\\infty\\) or \\(-\\infty\\) can be viewed as an eventual behavior as well :</p>  $a\\to \\infty$   $ \\ \\ $ is equivalent to   $\\forall M&gt;0, \\ $ $a$ is eventually in $\\{x\\in \\mathbb{R} \\ \\vert \\ x\\geq M\\}$   $a\\to -\\infty$   is equivalent to   $\\forall M&lt;0, \\ $ $a$ is eventually in $\\{x\\in \\mathbb{R} \\ \\vert \\ x\\leq M\\}$"},{"location":"blog/2025/09/21/a-technique-for-constructing-subsequences/","title":"A technique for constructing subsequences","text":"<p>Say we are given a sequence \\((a_n)\\) from which we would like to construct a subsequence \\((a_{n_k})\\). We can think of each \\(a_n\\) as a fish flowing down a river, and they do so in sequence; first comes the fish \\(a_1\\), then \\(a_2\\), and so on. The idea here is to set up a \"fishing net\". Depending on the net, some fish can easily swim through while others may get caught. As the sequence of fish \\(a_1, a_2, \\ldots\\) attempt to swim through the net, we note down each time a fish gets caught and that is how we construct our subsequence. Of course, in order for all of this to work we have to make sure that our \"net\" does not eventually run out of fish to catch. </p> <p>If \\((a_n)\\) is a sequence of points from some space \\(X\\), we can formally think of a \"net\" as a subset \\(N\\subseteq X\\). A fish \\(x\\in X\\) is caught by \\(N\\) if \\(x\\in N\\), otherwise the fish is able to swim past the net. The condition ensuring that \\(N\\) does not eventually run out of fish to catch (i.e. that \\(N\\) is a valid net) can be formally expressed as : The set \\(\\{n\\in \\mathbb{N} \\ \\vert \\ a_n\\in N\\}\\) is countable. In other words, \\(a_n\\in N\\) for infinitely many \\(n\\in \\mathbb{N}\\).</p> <p>Example</p> <p>For the space \\(X=\\mathbb{N}\\) and the sequence \\((1,2,3,\\ldots)\\), the subset \\(P\\) of prime numbers is a valid \"net\". Let us run through, step-by-step, the construction of a subsequence using this net. </p> <ul> <li>First comes the fish \"1\"; it swims past the net since 1 is not prime. </li> <li>Next comes the fish \"2\"; it gets caught in the net since 2 is prime. </li> <li>Next comes the fish \"3\"; it also gets caught. </li> <li>Next comes the fish \"4\"; it swims past the net just like fish \"1\". </li> </ul> <p>Our sequence of caught fish so far is \"2\", then \"3\" and should we continue this process ad infinitum we would end up with the subsequence \\((2,3,5,7,\\ldots)\\) of prime numbers.  </p> <p>Instead of restricting ourselves to a single net, we can construct more complicated subsequences by preparing a sequence of nets, the idea being that we switch to the next net each time a fish is caught. If \\(N_1, N_2,\\ldots\\) is a sequence of valid nets for \\((a_n)\\), the resulting subsequence \\((a_{n_k})\\) satisfies \\(a_{n_k}\\in N_k\\) for each \\(k\\) by construction. Here is an example of implementing this idea in practice :</p> <p>Theorem. There exists a sequence \\((a_n)\\) such that for every \\(L\\in \\mathbb{R}\\), there is a subsequence of \\((a_n)\\) that converges to \\(L\\).</p> Proof <p>Since the rational numbers are countable we can enumerate them. The idea is to treat this enumeration as a sequence of points in \\(\\mathbb{R}\\), let us call this sequence \\((q_n)\\).</p> <p>For each \\(k=1,2,\\ldots\\) define \\(I_k := (L-1/k, L+1/k)\\). Since \\(\\mathbb{Q}\\) is dense in \\(\\mathbb{R}\\), each \\(I_k\\) is a valid net for \\((q_n)\\). Thus, there is a subsequence \\((q_{n_k})\\) of \\((q_n)\\) such that \\(L-1/k &lt; q_{n_k} &lt; L+1/k\\) for each \\(k\\). By the Squeeze Theorem, \\((q_{n_k})\\to L\\) so we are done.  \\(\\Box\\) </p>"},{"location":"blog/2025/09/21/sums-over-countable-spaces/","title":"Sums over Countable Spaces","text":""},{"location":"blog/2025/09/21/sums-over-countable-spaces/#the-finite-case","title":"The Finite Case","text":"<p>Suppose I have a space \\(X\\) with three elements, we can represent this space with the set \\(\\{\\alpha, \\beta, \\gamma\\}\\). I want to be able to talk about sums over this space. Of course, \\(\\alpha + \\beta + \\gamma\\) doesn't make any sense. The elements of \\(X\\) simply serve as placeholders for the values that we want to add, in other words, we are using the \"three-ness\" of the space \\(X\\) to define a sum of three values. We can do this by assigning to each element \\(x\\in X\\) a real number \\(r\\in \\mathbb{R}\\), i.e. by defining a weight function \\(w:X\\to \\mathbb{R}\\). The sum over the space \\(X\\) with respect to the weight \\(w\\) is then simply \\(\\sum_{x\\in X}w(x) = w(\\alpha) + w(\\beta) + w(\\gamma)\\).</p> <p>This works fine for finite spaces, but if \\(X\\) is countably infinite then we quickly run into some problems. For example, we can try to define the sum this way : Since \\(X\\) is countably infinite, then there is a bijection \\(g:\\mathbb{N}\\to X\\). By indexing the elements of \\(X\\), we can definte the sum as an infinite series :</p> \\[ \\sum_{n=1}^\\infty{w(g(n))} \\] <p>However, in addition to convergence issues, it is also not entirely obvious if a different choice of \\(g\\) (a different rearrangement of the sum) will change the evaluation of the sum<sup>1</sup>. It turns out we can solve these issues by working in the space \\([0,\\infty]\\). We can do this by setting the codomain of our weight function to the space \\([0,\\infty]\\). </p> <p>The Space \\([0,\\infty]\\)</p> <p>This space is constructed by adding a point \"\\(\\infty\\)\" to the space \\([0,\\infty)\\). We can think of \\([0,\\infty]\\) as a linearly ordered topological space where the order on \\([0,\\infty)\\) is extended by setting \\(x\\leq \\infty\\) for all \\(x\\in [0,\\infty]\\). Furthermore, we extend addition on this space by setting \\(\\infty + x = x+\\infty = \\infty\\) for all \\(x\\in [0,\\infty]\\). </p> <ul> <li>The order on \\([0,\\infty]\\) is complete, i.e. any subset of \\([0,\\infty]\\) has a supremum.</li> <li>We can also talk about the convergence of sequences in \\([0,\\infty]\\) via its order topology. </li> </ul> <p>Due to the monotone convergence theorem, our sum has to converge to some \\(x\\in[0,\\infty]\\). Intuitively, the order of summation should also not matter if we only concern ourselves with adding non-negative terms although we will prove this rigorously later on. </p>"},{"location":"blog/2025/09/21/sums-over-countable-spaces/#the-general-case","title":"The General Case","text":"<p>With all this in mind, we come up with the following \"order-free\" definition for the sum over a countable space \\(X\\) by taking the supremum over all finite sub-sums :</p> <p>Definition 1. Let \\(X\\) be a countable space. We define the sum over a subset \\(A\\subseteq X\\) with respect to some weight \\(w:X\\to [0,\\infty]\\) with \\(\\mu_w(A)\\), where</p> \\[ \\mu_w(A) := \\sup\\left\\{\\sum_{x\\in F}w(x) \\ \\vert \\ F\\subseteq A, \\ \\text{finite }F \\right\\}, \\] <p>Reminder. Since we are working in the space \\([0,\\infty]\\), the supremum always exists (set \\(\\sup A := \\infty\\) if \\(A\\) is unbounded), thus \\(\\mu_w(A)\\) is well-defined. If there is no confusion, we may drop the weight in the notation.</p> <p>Here are some notes that may be useful :</p> <p>Note 1</p> <p>If \\(A\\) is finite then \\(\\mu(A)\\) reduces to the finite sum \\(\\sum_{x\\in A}w(x)\\). Notice for \\(A=\\varnothing\\) we are adding nothing so that \\(\\mu(\\varnothing) = 0\\).</p> <p>Note 2</p> <p>For any \\(A\\subseteq B\\) we have \\(\\mu(A)\\leq \\mu(B)\\) purely because</p> \\[ \\left\\{\\sum_{x\\in F}w(x) \\ \\vert \\ F\\subseteq A, \\ \\text{finite }F \\right\\} \\subseteq \\left\\{\\sum_{x\\in F}w(x) \\ \\vert \\ F\\subseteq B, \\ \\text{finite }F \\right\\} \\] <p>Note 3</p> <p>To prove \\(\\mu(A)\\leq r\\) it suffices to show that \\(r\\) is an upper bound of \\(\\{\\sum_{x\\in F}w(x) \\ \\vert \\  F\\subseteq A, \\ \\text{finite }F\\}\\), i.e. that for any finite \\(F\\subseteq A\\) we have \\(\\sum_{x\\in F}w(x) \\leq r\\). On the other hand, to show that \\(r\\leq \\mu(A)\\) it suffices to show that there exists a finite \\(F\\subseteq A\\) such that \\(r\\leq \\sum_{x\\in F}w(x)\\).</p>"},{"location":"blog/2025/09/21/sums-over-countable-spaces/#increasing-sequences-of-subsets","title":"Increasing Sequences of Subsets","text":"<p>Definition 2. Let \\(A \\subseteq X\\). We say that a sequence of sets \\(\\{A_n\\}_{n\\in \\mathbb{N}}\\) increases to \\(A\\) (denoted \\(A_n\\nearrow A\\)) if the following are satisfied : </p> <ul> <li>\\(A_1\\subseteq A_2\\subseteq \\cdots \\subseteq A\\) and </li> <li>\\(\\bigcup_{n=1}^\\infty A_n = A\\)</li> </ul> <p>Note. To prove the second condition, it suffices to show that for every \\(x\\in A\\) there exists an \\(N\\in \\mathbb{N}\\) such that \\(x\\in A_N\\). </p> <p>The following lemmas allow us to reframe our arguments in terms of sequences which should prove helpful later on :</p> <p>Lemma 1. For any \\(A \\subseteq X\\) there exists a sequence of finite sets that increases to \\(A\\).</p> Proof <p>If \\(A\\) is finite, then this is trivial. Suppose \\(A\\) is countably infinite, then there exists a bijection \\(g:\\mathbb{N}\\to A\\). For each \\(n: \\mathbb{N}\\) define \\(A_n := \\{g(i) : i\\leq n\\}\\). It is pretty clear that \\(A_1\\subseteq A_2\\subseteq \\cdots \\subseteq A\\) and that each \\(A_n\\) is finite.</p> <p>Now suppose \\(x\\in A\\), then there exists an \\(N\\in \\mathbb{N}\\) such that \\(x = g(N)\\in A_N\\) by definition. Thus \\(A_n\\nearrow A\\) as needed.</p> <p>Lemma 2. For any \\(A \\subseteq X\\) and \\(A_n\\nearrow A\\), we have \\(\\mu(A_n)\\to \\mu(A)\\).</p> Proof <p>By Note 2 we have \\(\\mu(A_1)\\leq \\mu(A_2)\\leq \\cdots \\leq \\mu(A)\\), thus \\(\\mu(A_n)\\) converges to some \\(L\\in [0,\\infty]\\) with \\(L\\leq \\mu(A)\\) by the Monotone Convergence Theorem. Now it suffices to show that \\(\\mu(A)\\leq L\\) (Note 3). Suppose \\(F\\subseteq A\\) is finite then there is an \\(N\\in \\mathbb{N}\\) large enough so that \\(F\\subseteq A_N\\), thus :</p> \\[ \\sum_{x\\in F}w(x) \\leq \\mu(A_N)\\leq L \\] <p>so we are done.</p> <p>Combining these two lemmas, we get the following :</p> <p>Theorem 1. For any \\(A\\subseteq X\\) there exists a sequence \\(A_1, A_2, \\ldots\\) of finite sets such that \\(\\mu(A_n)\\to \\mu(A)\\). </p>"},{"location":"blog/2025/09/21/sums-over-countable-spaces/#countable-additivity","title":"Countable Additivity","text":"<p>Lemma 3 (Finite Additivity). Let \\(A_1, A_2, \\cdots, A_N \\subseteq X\\) be a finite collection of pairwise disjoint sets, then :</p> <p>$$ \\mu\\left(\\bigcup_{n=1}^N A_n\\right) = \\sum_{n=1}^N \\mu(A_n). $$</p> Proof <p>It suffices to show that for any disjoint \\(A,B \\subseteq X\\) we have \\(\\mu(A\\cup B) = \\mu(A) + \\mu(B)\\); the rest of the argument follows inductively. Also notice that the above identity is trivial for finite \\(A\\) and \\(B\\).</p> <p>Part 1 : \\(\\mu(A\\cup B)\\leq \\mu(A) + \\mu(B)\\). </p> <p>Suppose \\(F\\subseteq A\\cup B\\) is finite. Now define \\(F_1 = F\\cap A, \\ F_2 = F\\cap B\\). Notice that \\(F = F_1 \\cup F_2\\) and that \\(F_1, F_2\\) are disjoint. Thus,</p> \\[ \\mu(F) = \\mu(F_1) + \\mu(F_2) \\leq \\mu(A) + \\mu(B).\\] <p>In other words, we have shown that \\(\\mu(F)\\leq \\mu(A) + \\mu(B)\\) for any finite \\(F\\subseteq A\\cup B\\) which is equivalent to our goal (see note 3).</p> <p>Part 2 : \\(\\mu(A) + \\mu(B)\\leq \\mu(A\\cup B)\\). </p> <p>For any finite \\(F_1\\subseteq A\\) and \\(F_2\\subseteq B\\), notice \\(F_1, F_2\\) are disjoint so that</p> \\[ \\mu(F_1) + \\mu(F_2) = \\mu(F_1\\cup F_2) \\leq \\mu(A\\cup B).\\] <p>Now we Theorem 1 : There exists a sequence \\(\\{A_n\\}_{n\\in \\mathbb{N}}\\) such that each \\(A_n\\) is finite and \\(\\mu(A_n)\\to \\mu(A)\\) (and the same for \\(B\\)). Thus, for each \\(n\\in \\mathbb{N}\\), </p> \\[ \\mu(A_n) + \\mu(B_n) \\leq \\mu(A\\cup B).\\] <p>Taking the limit as \\(n\\to \\infty\\) gives \\(\\mu(A)+ \\mu(B)\\leq \\mu(A\\cup B)\\) as desired.</p> <p>Theorem 2. (Countable Additivity). Suppose \\(A=\\bigcup_{n=1}^\\infty{A_n} \\subseteq X\\) and the \\(A_n\\) are pairwise disjoint, i.e. \\(\\{A_n\\}_{n\\in \\mathbb{N}}\\) is a partition of \\(A\\), then</p> <p>$$ \\mu(A) = \\sum_{n=1}^\\infty \\mu(A_n). $$</p> Proof <p>Part 1 : \\(\\mu(A)\\leq \\sum_{n=1}^\\infty \\mu(A_n)\\)</p> <p>Suppose \\(F\\subseteq A\\) is finite then only a finite number of \\(A_n\\)'s are needed to cover \\(F\\). Thus there is an \\(N\\in \\mathbb{N}\\) large enough so that \\(F\\subseteq \\bigcup_{n=1}^N A_{n}\\) and by finite additivity</p> \\[ \\mu(F) \\leq \\mu\\left( \\bigcup_{n=1}^N A_{n} \\right) = \\sum_{n=1}^N \\mu(A_{n}) \\leq \\sum_{n=1}^\\infty \\mu(A_n). \\] <p>Part 2 : \\(\\sum_{n=1}^\\infty \\mu(A_n)\\leq \\mu(A)\\)</p> <p>By finite additivity, for any \\(N\\in \\mathbb{N}\\)</p> \\[ \\sum_{n=1}^N \\mu(A_n) = \\mu\\left( \\bigcup_{n=1}^N A_n \\right) \\leq \\mu(A).\\] <p>Taking \\(N\\to \\infty\\) gives us the result we need.</p>"},{"location":"blog/2025/09/21/sums-over-countable-spaces/#sum-partitions","title":"Sum Partitions","text":"<p>Suppose we were to use \\(\\mu\\) to define sums over the space \\(\\mathbb{N}\\), would that be equivalent to the traditional infinite sum? In other words, given some weight \\(w:\\mathbb{N}\\to [0,\\infty]\\), is \\(\\mu(\\mathbb{N}) = \\sum_{n=1}^\\infty w(n)\\)? The LHS is defined by a supremum over all finite sums whereas the RHS is defined by the limit of its partial sums so this is not immediately obvious, but countable additivity (Theorem 2) makes this almost trivial. </p> <p>We can partition \\(\\mathbb{N}\\) into the sets \\(A_1 = \\{1\\}, \\ A_2 = \\{2\\}, \\ \\ldots\\) Notice that \\(\\mu(A_n) = w(n)\\) for each \\(n\\in \\mathbb{N}\\) thus by countable additivity \\(\\mu(\\mathbb{N}) = \\sum_{n=1}^\\infty \\mu(A_n) = \\sum_{n=1}^\\infty w(n)\\). Similarly, if \\(g:\\mathbb{N}\\to \\mathbb{N}\\) is a bijection, then the sets \\(A_n = \\{g(n)\\}\\) form a partition of \\(\\mathbb{N}\\) so \\(\\mu(\\mathbb{N}) = \\sum_{n=1}^\\infty w(g(n))\\). In other words, infinite sums of non-negative terms are order-invariant. </p> <p>We can also partition \\(\\mathbb{N}\\) into its odd and even parts, further partition those into the sets \\(O_n = \\{2n-1\\}, \\ E_n = \\{2n\\}\\) for \\(n=1,2,\\ldots\\) and use countable additivity :</p> \\[ \\begin{align*} \\mu(\\mathbb{N}) &amp;= \\mu(\\mathbb{N}_{\\text{odd}}) + \\mu(\\mathbb{N}_{\\text{even}}) \\\\ &amp;= \\sum_{n=1}^\\infty \\mu(O_n) + \\sum_{n=1}^\\infty \\mu(E_n) \\\\ &amp;= \\sum_{n=1}^\\infty w(2n-1) + \\sum_{n=1}^\\infty w(2n)  \\end{align*} \\] <p>The point is that infinite sums (with non-negative terms) can be broken down and summed piece by piece in any order which may be helpful for simplifications.</p>"},{"location":"blog/2025/09/21/sums-over-countable-spaces/#tonellis-theorem-discrete","title":"Tonelli's Theorem (Discrete)","text":"<p>The space \\(\\mathbb{N}^2\\) can be visualized as an infinite 2d matrix. A weight \\(w:\\mathbb{N}^2\\to [0,\\infty]\\) on this space can be visualized by setting the entry at the \\(n\\)-th row and \\(m\\)-th column of the matrix to equal \\(w(n,m)\\). Summing over \\(\\mathbb{N}^2\\) is therefore summing over all entries of the corresponding matrix. Tonelli's Theorem states that if all entries are non-negative, then summing across all rows is equivalent to summing across all columns. More formally, we can define the subsets </p> \\[ R_n = \\{(n,i) \\ \\vert \\  i\\in\\mathbb{N}\\}, \\quad C_n = \\{(i,n) \\ \\vert \\ i\\in\\mathbb{N}\\} \\] <p>to specify the rows and columns of the matrix respectively. Thus Tonelli's Theorem states that :</p> \\[ \\sum_{n=1}^\\infty \\mu(R_n) = \\sum_{n=1}^\\infty \\mu(C_n) \\] <p>which is trivial by countable additivity. Note that \\(\\mu(R_n) = \\sum_{i=1}^\\infty w(n,i)\\) and \\(\\mu(C_n) = \\sum_{i=1}^\\infty w(i,n)\\), thus we can restate the above as a double sum :</p> \\[ \\begin{align*} \\sum_{n=1}^\\infty \\sum_{i=1}^\\infty w(n,i) &amp;= \\sum_{n=1}^\\infty \\sum_{i=1}^\\infty w(i,n) \\\\ &amp;= \\sum_{i=1}^\\infty \\sum_{n=1}^\\infty w(n,i), \\quad \\quad \\text{(relabel/swap index)} \\end{align*} \\] <ol> <li> <p>In fact the choice of \\(g\\) does matter, see the Riemann Rearrangement Theorem \u21a9</p> </li> </ol>"},{"location":"blog/archive/2025/10/","title":"October 2025","text":""},{"location":"blog/archive/2025/09/","title":"September 2025","text":""},{"location":"blog/category/tilc/","title":"TILC","text":""},{"location":"blog/category/japanese/","title":"Japanese","text":""},{"location":"blog/category/maths/","title":"Maths","text":""}]}